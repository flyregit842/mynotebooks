{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01db8e22-ed71-4bb5-92da-431c0aca99ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 0: Install Required Packages and Environment Setup\n",
    "from IPython.display import clear_output; clear_output(wait=True)\n",
    "print(\"STEP 0: Installing required packages...\")\n",
    "\n",
    "!pip install azure-cognitiveservices-speech pysubs2 pillow snownlp python-dotenv tqdm pyyaml --quiet\n",
    "!pip install ipywidgets --upgrade\n",
    "print(\"STEP 0 Complete! All packages installed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb21748-7f5b-407d-9ad5-512cdac8d036",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 1: Project Initialization and Config Load\n",
    "from IPython.display import clear_output; clear_output(wait=True)\n",
    "print(\"STEP 1: Initializing project and loading config...\")\n",
    "\n",
    "import os\n",
    "import yaml\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Set main working directory\n",
    "main_dir = os.getcwd()\n",
    "subdir = main_dir  # All operations will happen in the main workspace\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "AZURE_SPEECH_KEY = os.environ.get(\"AZURE_SPEECH_KEY\")\n",
    "AZURE_SPEECH_REGION = os.environ.get(\"AZURE_SPEECH_REGION\")\n",
    "MINIMAX_SPEECH_KEY = os.environ.get(\"MINIMAX_SPEECH_KEY\")\n",
    "OPENAI_API_KEY = os.environ.get(\"OPENAI_API_KEY\")\n",
    "\n",
    "if not AZURE_SPEECH_KEY or not AZURE_SPEECH_REGION or not MINIMAX_SPEECH_KEY or not OPENAI_API_KEY:\n",
    "    raise ValueError(\"Missing one or more required keys in .env file: AZURE_SPEECH_KEY, AZURE_SPEECH_REGION, MINIMAX_SPEECH_KEY, or OPENAI_API_KEY!\")\n",
    "\n",
    "# Load config.yaml if it exists, otherwise use empty config\n",
    "if os.path.exists('config.yaml'):\n",
    "    with open('config.yaml', encoding='utf-8') as f:\n",
    "        config = yaml.safe_load(f)\n",
    "else:\n",
    "    config = {}\n",
    "\n",
    "print(\"=\"*40)\n",
    "print(f\"專案名稱: {config.get('project_title', config.get('title', '未設定'))}\")\n",
    "print(f\"Current subdir: {subdir}\")\n",
    "print(f\"目前工作目錄：{os.getcwd()}\")\n",
    "print(\"=\"*40)\n",
    "# print(\"STEP 1 Complete!\")\n",
    "from datetime import datetime\n",
    "print(f\"STEP 1 Complete! {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ddf9c6b-3fdf-4efc-8a4c-ebd78fff9f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: 完整 TTS 參數與 UI，正確保存主文字到 text.txt（Azure SSML/Minimax全參數）\n",
    "# 必填：.env 需有 AZURE_SPEECH_KEY, AZURE_SPEECH_REGION, MINIMAX_SPEECH_KEY, MINIMAX_GROUP_ID\n",
    "\n",
    "import os\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output, Audio\n",
    "import yaml\n",
    "import tempfile\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "clear_output(wait=True)\n",
    "\n",
    "# ===== Step 2.1: Project Info =====\n",
    "label_style = {'description_width': '120px'}\n",
    "wide_layout = widgets.Layout(width='1100px')\n",
    "\n",
    "project_title_widget = widgets.Text(value='', description='專案名稱:', style=label_style, layout=wide_layout)\n",
    "project_author_widget = widgets.Text(value='', description='作者:', style=label_style, layout=wide_layout)\n",
    "bgm_volume_widget = widgets.FloatSlider(value=0.3, min=0, max=1, step=0.01, description='BGM音量:', style=label_style, layout=wide_layout)\n",
    "attribution_widget = widgets.Text(value='', description='版權說明:', style=label_style, layout=wide_layout)\n",
    "subtitle_font_widget = widgets.Text(value='NotoSansCJKtc-Regular.otf', description='字幕字型:', style=label_style, layout=wide_layout)\n",
    "subtitle_fontsize_widget = widgets.IntSlider(value=30, min=10, max=80, step=1, description='字幕字體大小:', style=label_style, layout=wide_layout)\n",
    "video_resolution_widget = widgets.Text(value='1920,1080', description='影片解析度:', style=label_style, layout=wide_layout)\n",
    "background_file_widget = widgets.Text(value='background.jpg', description='背景檔:', style=label_style, layout=wide_layout)\n",
    "bgm_file_widget = widgets.Text(value='bgm.mp3', description='BGM檔:', style=label_style, layout=wide_layout)\n",
    "thumbnail_file_widget = widgets.Text(value='thumbnail.jpg', description='縮圖檔:', style=label_style, layout=wide_layout)\n",
    "text_file_widget = widgets.Text(value='text.txt', description='文字檔:', style=label_style, layout=wide_layout)\n",
    "\n",
    "project_info_box = widgets.VBox([\n",
    "    project_title_widget, project_author_widget, bgm_volume_widget, attribution_widget,\n",
    "    subtitle_font_widget, subtitle_fontsize_widget, video_resolution_widget,\n",
    "    background_file_widget, bgm_file_widget, thumbnail_file_widget, text_file_widget\n",
    "])\n",
    "\n",
    "# ===== Step 2.2: Main Text & Preview =====\n",
    "input_text_widget = widgets.Textarea(value='', description='主文字:', style=label_style, layout=widgets.Layout(width='1100px', height='150px'))\n",
    "preview_text_widget = widgets.Textarea(value='', description='試聽文字:', style=label_style, layout=widgets.Layout(width='1100px', height='80px'))\n",
    "preview_button = widgets.Button(description='語音試聽', button_style='info', layout=widgets.Layout(width='350px', height='50px'))\n",
    "audio_output = widgets.Output(layout=wide_layout)\n",
    "\n",
    "# ===== Step 2.3: TTS Server 選擇下拉選單 =====\n",
    "tts_server_widget = widgets.Dropdown(\n",
    "    options=['azure', 'minimax'],\n",
    "    value='azure',\n",
    "    description='TTS Server(供Step4/5使用):',\n",
    "    style=label_style, layout=wide_layout\n",
    ")\n",
    "\n",
    "# ===== Step 2.4: TTS Tabs UI =====\n",
    "# --- Azure ---\n",
    "azure_voice_widget = widgets.Dropdown(\n",
    "    options=['zh-TW-YunJheNeural', 'zh-TW-HsiaoChenNeural', 'zh-CN-YunxiNeural', 'en-US-AriaNeural', 'en-US-GuyNeural', 'ja-JP-NanamiNeural', 'ja-JP-KeitaNeural'],\n",
    "    value='zh-TW-YunJheNeural', description='語音:', style=label_style, layout=wide_layout)\n",
    "azure_format_widget = widgets.Dropdown(\n",
    "    options=['mp3', 'wav', 'ogg', 'pcm'], value='mp3', description='音檔格式:', style=label_style, layout=wide_layout)\n",
    "\n",
    "azure_box = widgets.VBox([\n",
    "    widgets.HTML('<b>Azure TTS 設定（語音可選，SSML自動生成）</b>'),\n",
    "    azure_voice_widget, azure_format_widget\n",
    "])\n",
    "\n",
    "# --- MINIMAX ---\n",
    "minimax_model_widget = widgets.Dropdown(\n",
    "    options=['speech-02-hd', 'speech-2.5-hd-preview'], value='speech-02-hd', description='模型:', style=label_style, layout=wide_layout)\n",
    "minimax_accent_widget = widgets.Dropdown(\n",
    "    options=['Chinese (Mandarin)', 'English', 'Japanese'], value='Chinese (Mandarin)', description='腔調:', style=label_style, layout=wide_layout)\n",
    "minimax_voice_widget = widgets.Dropdown(\n",
    "    options=['Chinese (Mandarin)_Warm_Bestie', 'Chinese (Mandarin)_Bright_Light', 'English_Graceful_Lady', 'Japanese_Whisper_Belle'],\n",
    "    value='Chinese (Mandarin)_Warm_Bestie', description='語音:', style=label_style, layout=wide_layout)\n",
    "minimax_emotion_widget = widgets.Dropdown(\n",
    "    options=['calm', 'happy', 'sad', 'angry', 'fearful', 'disgusted', 'surprised'], value='calm', description='情感:', style=label_style, layout=wide_layout)\n",
    "minimax_speed_widget = widgets.FloatSlider(\n",
    "    value=1.0, min=0.5, max=2.0, step=0.01, description='語速:', style=label_style, layout=wide_layout)\n",
    "minimax_pitch_widget = widgets.IntSlider(\n",
    "    value=0, min=-12, max=12, step=1, description='語調(半音):', style=label_style, layout=wide_layout)\n",
    "minimax_vol_widget = widgets.FloatSlider(\n",
    "    value=1.0, min=0.1, max=10.0, step=0.1, description='音量:', style=label_style, layout=wide_layout)\n",
    "minimax_format_widget = widgets.Dropdown(\n",
    "    options=['mp3', 'wav'], value='mp3', description='音檔格式:', style=label_style, layout=wide_layout)\n",
    "minimax_sample_widget = widgets.Dropdown(\n",
    "    options=[32000, 44100], value=32000, description='取樣率:', style=label_style, layout=wide_layout)\n",
    "minimax_bitrate_widget = widgets.Dropdown(\n",
    "    options=[128000, 256000], value=128000, description='比特率:', style=label_style, layout=wide_layout)\n",
    "minimax_channel_widget = widgets.Dropdown(\n",
    "    options=[1, 2], value=1, description='聲道:', style=label_style, layout=wide_layout)\n",
    "minimax_lang_boost_widget = widgets.Dropdown(\n",
    "    options=['auto', 'none', 'zh', 'en', 'ja'], value='auto', description='語言加強:', style=label_style, layout=wide_layout)\n",
    "minimax_subtitle_enable_widget = widgets.Checkbox(\n",
    "    value=False, description='字幕啟用:', style=label_style)\n",
    "\n",
    "minimax_box = widgets.VBox([\n",
    "    widgets.HTML('<b>MINIMAX TTS 設定</b>'),\n",
    "    minimax_model_widget,\n",
    "    minimax_accent_widget, minimax_voice_widget, minimax_emotion_widget,\n",
    "    minimax_speed_widget, minimax_pitch_widget, minimax_vol_widget,\n",
    "    minimax_format_widget, minimax_sample_widget, minimax_bitrate_widget, minimax_channel_widget,\n",
    "    minimax_lang_boost_widget, minimax_subtitle_enable_widget\n",
    "])\n",
    "\n",
    "tts_tab = widgets.Tab(children=[azure_box, minimax_box])\n",
    "tts_tab.set_title(0, 'Azure TTS')\n",
    "tts_tab.set_title(1, 'MINIMAX TTS')\n",
    "\n",
    "# ===== Step 2.4: TTS API Functions =====\n",
    "def azure_tts(text, voice, output_format_key):\n",
    "    load_dotenv()\n",
    "    AZURE_SPEECH_KEY = os.getenv('AZURE_SPEECH_KEY')\n",
    "    AZURE_SPEECH_REGION = os.getenv('AZURE_SPEECH_REGION')\n",
    "    AZURE_FORMAT_MAP = {\n",
    "        \"mp3\": \"audio-16khz-32kbitrate-mono-mp3\",\n",
    "        \"wav\": \"riff-24khz-16bit-mono-pcm\",\n",
    "        \"ogg\": \"ogg-48khz-16bit-mono-opus\",\n",
    "        \"pcm\": \"raw-16khz-16bit-mono-pcm\"\n",
    "    }\n",
    "    output_format = AZURE_FORMAT_MAP.get(output_format_key, \"audio-16khz-32kbitrate-mono-mp3\")\n",
    "    url = f\"https://{AZURE_SPEECH_REGION}.tts.speech.microsoft.com/cognitiveservices/v1\"\n",
    "    headers = {\n",
    "        \"Ocp-Apim-Subscription-Key\": AZURE_SPEECH_KEY,\n",
    "        \"Content-Type\": \"application/ssml+xml\",\n",
    "        \"X-Microsoft-OutputFormat\": output_format,\n",
    "        \"User-Agent\": \"TTSClient\"\n",
    "    }\n",
    "    ssml = f\"\"\"<speak version='1.0' xml:lang='zh-TW'>\n",
    "        <voice name='{voice}'>{text}</voice>\n",
    "    </speak>\"\"\"\n",
    "    try:\n",
    "        r = requests.post(url, headers=headers, data=ssml.encode('utf-8'))\n",
    "        if r.status_code == 200:\n",
    "            with tempfile.NamedTemporaryFile(delete=False, suffix=f'.{output_format_key}') as tf:\n",
    "                tf.write(r.content)\n",
    "                return tf.name\n",
    "        else:\n",
    "            print(\"Azure TTS API失敗，狀態碼：\", r.status_code)\n",
    "            print(\"回應：\", r.text[:300])\n",
    "            print(\"Endpoint:\", url)\n",
    "            print(\"Headers:\", headers)\n",
    "            print(\"Payload used:\\n\", ssml)\n",
    "    except Exception as e:\n",
    "        print('Azure TTS error:', e)\n",
    "    return None\n",
    "\n",
    "def minimax_tts(text, model, accent, voice, emotion, speed, pitch, vol, fmt, sample_rate, bitrate, channel, lang_boost, subtitle_enable):\n",
    "    try:\n",
    "        load_dotenv()\n",
    "        MINIMAX_SPEECH_KEY = os.getenv('MINIMAX_SPEECH_KEY')\n",
    "        GROUP_ID = os.getenv('MINIMAX_GROUP_ID', '1982992498867311582')\n",
    "        url = f\"https://api.minimax.io/v1/t2a_v2?GroupId={GROUP_ID}\"\n",
    "        headers = {\n",
    "            \"Authorization\": f\"Bearer {MINIMAX_SPEECH_KEY}\",\n",
    "            \"Content-Type\": \"application/json\"\n",
    "        }\n",
    "        payload = {\n",
    "            \"model\": model,\n",
    "            \"text\": text,\n",
    "            \"voice_setting\": {\n",
    "                \"voice_id\": voice,\n",
    "                \"speed\": speed,\n",
    "                \"vol\": vol,\n",
    "                \"pitch\": pitch,\n",
    "                \"emotion\": emotion\n",
    "            },\n",
    "            \"audio_setting\": {\n",
    "                \"sample_rate\": sample_rate,\n",
    "                \"bitrate\": bitrate,\n",
    "                \"format\": fmt,\n",
    "                \"channel\": channel\n",
    "            },\n",
    "            \"output_format\": \"url\",\n",
    "            \"language_boost\": lang_boost,\n",
    "            \"subtitle_enable\": subtitle_enable\n",
    "        }\n",
    "        r = requests.post(url, headers=headers, json=payload)\n",
    "        if r.status_code == 200:\n",
    "            data = r.json()\n",
    "            base_resp = data.get(\"base_resp\", {})\n",
    "            if base_resp.get(\"status_code\") == 0:\n",
    "                audio_url = data.get(\"data\", {}).get(\"audio\")\n",
    "                if audio_url:\n",
    "                    r2 = requests.get(audio_url)\n",
    "                    if r2.status_code == 200:\n",
    "                        with tempfile.NamedTemporaryFile(delete=False, suffix=f'.{fmt}') as tf:\n",
    "                            tf.write(r2.content)\n",
    "                            return tf.name\n",
    "                    else:\n",
    "                        print(\"MINIMAX音檔下載失敗：\", r2.status_code)\n",
    "                else:\n",
    "                    print(\"MINIMAX未取得音檔URL，請檢查API回應！\")\n",
    "            else:\n",
    "                print(\"MINIMAX API錯誤：\", base_resp.get(\"status_msg\"))\n",
    "        else:\n",
    "            print(\"MINIMAX TTS API失敗，狀態碼：\", r.status_code)\n",
    "            print(\"回應：\", r.text[:300])\n",
    "            print(\"Payload used:\\n\", payload)\n",
    "    except Exception as e:\n",
    "        print(\"MINIMAX TTS試聽錯誤：\", e)\n",
    "    return None\n",
    "\n",
    "# ===== Step 2.5: Preview Button Logic =====\n",
    "def on_preview_clicked(b):\n",
    "    with audio_output:\n",
    "        audio_output.clear_output()\n",
    "        text = preview_text_widget.value.strip()\n",
    "        if not text:\n",
    "            print(\"請輸入試聽文字\")\n",
    "            return\n",
    "\n",
    "        audio_path = None\n",
    "        # 根據 tts_server_widget 的選擇呼叫不同 TTS\n",
    "        if tts_server_widget.value == 'azure':\n",
    "            audio_path = azure_tts(\n",
    "                text,\n",
    "                azure_voice_widget.value,\n",
    "                azure_format_widget.value\n",
    "            )\n",
    "        else:  # MINIMAX\n",
    "            audio_path = minimax_tts(\n",
    "                text,\n",
    "                minimax_model_widget.value,\n",
    "                minimax_accent_widget.value,\n",
    "                minimax_voice_widget.value,\n",
    "                minimax_emotion_widget.value,\n",
    "                minimax_speed_widget.value,\n",
    "                minimax_pitch_widget.value,\n",
    "                minimax_vol_widget.value,\n",
    "                minimax_format_widget.value,\n",
    "                minimax_sample_widget.value,\n",
    "                minimax_bitrate_widget.value,\n",
    "                minimax_channel_widget.value,\n",
    "                minimax_lang_boost_widget.value,\n",
    "                minimax_subtitle_enable_widget.value\n",
    "            )\n",
    "        if audio_path:\n",
    "            display(Audio(audio_path, autoplay=True))\n",
    "        else:\n",
    "            print(\"語音產生失敗，請檢查API金鑰或設定。\")\n",
    "\n",
    "preview_button.on_click(on_preview_clicked)\n",
    "\n",
    "# ===== Step 2.7: Save Logic (正確: 寫入 tts_server 為字串到 config.yaml) =====\n",
    "output = widgets.Output(layout=wide_layout)\n",
    "def on_save_clicked(b):\n",
    "    config = {\n",
    "        'project_title': project_title_widget.value,\n",
    "        'project_author': project_author_widget.value,\n",
    "        'bgm_volume': bgm_volume_widget.value,\n",
    "        'attribution': attribution_widget.value,\n",
    "        'subtitle_font': subtitle_font_widget.value,\n",
    "        'subtitle_fontsize': subtitle_fontsize_widget.value,\n",
    "        'video_resolution': video_resolution_widget.value,\n",
    "        'background': background_file_widget.value,\n",
    "        'bgm': bgm_file_widget.value,\n",
    "        'thumbnail': thumbnail_file_widget.value,\n",
    "        'text': text_file_widget.value,\n",
    "        'input_text': input_text_widget.value,\n",
    "        'preview_text': preview_text_widget.value,\n",
    "        'tts_server': tts_server_widget.value,  # 修正：直接寫字串'azure'或'minimax'\n",
    "\n",
    "        # Azure TTS\n",
    "        'azure_voice': azure_voice_widget.value,\n",
    "        'azure_format': azure_format_widget.value,\n",
    "\n",
    "        # MINIMAX TTS\n",
    "        'minimax_model': minimax_model_widget.value,\n",
    "        'minimax_accent': minimax_accent_widget.value,\n",
    "        'minimax_voice': minimax_voice_widget.value,\n",
    "        'minimax_emotion': minimax_emotion_widget.value,\n",
    "        'minimax_speed': minimax_speed_widget.value,\n",
    "        'minimax_pitch': minimax_pitch_widget.value,\n",
    "        'minimax_vol': minimax_vol_widget.value,\n",
    "        'minimax_format': minimax_format_widget.value,\n",
    "        'minimax_sample_rate': minimax_sample_widget.value,\n",
    "        'minimax_bitrate': minimax_bitrate_widget.value,\n",
    "        'minimax_channel': minimax_channel_widget.value,\n",
    "        'minimax_language_boost': minimax_lang_boost_widget.value,\n",
    "        'minimax_subtitle_enable': minimax_subtitle_enable_widget.value\n",
    "    }\n",
    "    with output:\n",
    "        output.clear_output()\n",
    "        yaml.safe_dump(config, open('config.yaml', 'w', encoding='utf-8'), allow_unicode=True)\n",
    "        # --- 修正: 寫入主文字到 text.txt ---\n",
    "        try:\n",
    "            with open(text_file_widget.value, \"w\", encoding=\"utf-8\") as tf:\n",
    "                tf.write(input_text_widget.value)\n",
    "            print(f'主文字已正確寫入 {text_file_widget.value}！')\n",
    "        except Exception as e:\n",
    "            print(f'寫入 {text_file_widget.value} 時發生錯誤:', e)\n",
    "        print('所有設定已完整儲存到 config.yaml！')\n",
    "        print(config)\n",
    "\n",
    "save_button = widgets.Button(description='儲存全部設定', button_style='success', layout=widgets.Layout(width='350px', height='50px'))\n",
    "save_button.on_click(on_save_clicked)\n",
    "\n",
    "# ===== Step 2.7: Display Unified UI =====\n",
    "display(\n",
    "    widgets.HTML(\"<h3>Step 2：完整 YouTuber 專案設定 + TTS 調音（Azure / MINIMAX）</h3>\"),\n",
    "    project_info_box,\n",
    "    input_text_widget,\n",
    "    preview_text_widget,\n",
    "    preview_button,\n",
    "    audio_output,\n",
    "    tts_server_widget,  # TTS Server 選擇獨立顯示\n",
    "    tts_tab,\n",
    "    save_button,\n",
    "    output\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245507be-259b-48ec-8a32-af3752659877",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 3: Load, Clean, and Split Sentences from Text File\n",
    "from IPython.display import clear_output; clear_output(wait=True)\n",
    "print(\"STEP 3: Loading and cleaning sentences from text file...\")\n",
    "\n",
    "import yaml\n",
    "import os\n",
    "import re\n",
    "from snownlp import SnowNLP\n",
    "\n",
    "# Reload latest config (in case changed/reset)\n",
    "if os.path.exists('config.yaml'):\n",
    "    with open('config.yaml', encoding='utf-8') as f:\n",
    "        config = yaml.safe_load(f)\n",
    "else:\n",
    "    config = {}\n",
    "\n",
    "text_file = config.get('text', 'text.txt')\n",
    "if not os.path.exists(text_file):\n",
    "    print(f\"[ERROR] 找不到文字檔: {text_file}\")\n",
    "    sentences = []\n",
    "else:\n",
    "    # Load text and clean/split sentences\n",
    "    try:\n",
    "        with open(text_file, 'r', encoding='utf-8') as f:\n",
    "            raw_text = f.read().strip()\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Failed to read {text_file}: {e}\")\n",
    "        raw_text = \"\"\n",
    "\n",
    "    def is_pronounceable(s):\n",
    "        return bool(re.search(r'[\\u4e00-\\u9fffA-Za-z0-9]', s))\n",
    "\n",
    "    def clean_markdown(s):\n",
    "        s = re.sub(r\"^[#\\-\\*\\s>]+\", \"\", s)\n",
    "        s = re.sub(r\"(\\*|`|_|>|#|\\[|\\]|\\(|\\)|\\-|~|=|>)\", \"\", s)\n",
    "        s = re.sub(r\"[「」]\", \"\", s)\n",
    "        s = re.sub(r\"\\s+\", \" \", s)\n",
    "        return s.strip()\n",
    "\n",
    "    try:\n",
    "        sentences = [s.strip() for s in SnowNLP(raw_text).sentences if s.strip()]\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] SnowNLP sentence segmentation failed: {e}\")\n",
    "        sentences = [raw_text] if raw_text else []\n",
    "\n",
    "    sentences = [clean_markdown(s) for s in sentences if is_pronounceable(s)]\n",
    "    sentences = [s for s in sentences if is_pronounceable(s)]\n",
    "\n",
    "    print(f\"Total sentences after cleaning: {len(sentences)}\")\n",
    "    for idx, s in enumerate(sentences):\n",
    "        print(f\"{idx}: '{s}'\")\n",
    "\n",
    "print(\"STEP 3 Complete! Sentences loaded and cleaned.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59538010-a252-44b5-889b-ba7d5c6fe1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 4: TTS voice synthesis for each sentence (Azure/MINIMAX)\n",
    "from IPython.display import clear_output\n",
    "import os\n",
    "import yaml\n",
    "from dotenv import load_dotenv\n",
    "import requests\n",
    "import tempfile\n",
    "\n",
    "clear_output(wait=True)\n",
    "print(\"STEP 4: TTS voice synthesis for each sentence (Azure/MINIMAX)\")\n",
    "\n",
    "# 讀取 config.yaml\n",
    "if os.path.exists('config.yaml'):\n",
    "    with open('config.yaml', encoding='utf-8') as f:\n",
    "        config = yaml.safe_load(f)\n",
    "else:\n",
    "    config = {}\n",
    "\n",
    "sentences = config.get('input_text', '').split('\\n') if config.get('input_text') else []\n",
    "if not sentences:\n",
    "    print(\"[ERROR] No sentences found in config['input_text']\")\n",
    "print(f\"Total sentences to synthesize: {len(sentences)}\")\n",
    "\n",
    "tts_server = config.get('tts_server', 'azure')\n",
    "subdir = os.getcwd()\n",
    "failed_sentences = []\n",
    "\n",
    "if tts_server == 'azure':\n",
    "    import azure.cognitiveservices.speech as speechsdk\n",
    "    load_dotenv()\n",
    "    AZURE_SPEECH_KEY = os.environ.get(\"AZURE_SPEECH_KEY\")\n",
    "    AZURE_SPEECH_REGION = os.environ.get(\"AZURE_SPEECH_REGION\")\n",
    "    VOICE = config.get('azure_voice', 'zh-TW-YunJheNeural')\n",
    "    print(f\"[CHECK] Azure voice_id for synthesis: {VOICE}\")\n",
    "    for i, sentence in enumerate(sentences):\n",
    "        mp3_fname = os.path.join(subdir, f\"voice_{i}.mp3\")\n",
    "        if os.path.exists(mp3_fname):\n",
    "            overwrite = input(f\"{mp3_fname} 已存在，要覆蓋嗎？(y/n): \")\n",
    "            if overwrite.lower() != 'y':\n",
    "                print(f\"跳過 {mp3_fname}\")\n",
    "                continue\n",
    "        speech_config = speechsdk.SpeechConfig(subscription=AZURE_SPEECH_KEY, region=AZURE_SPEECH_REGION)\n",
    "        speech_config.speech_synthesis_voice_name = VOICE\n",
    "        speech_config.set_speech_synthesis_output_format(\n",
    "            speechsdk.SpeechSynthesisOutputFormat.Audio16Khz32KBitRateMonoMp3\n",
    "        )\n",
    "        audio_config = speechsdk.audio.AudioOutputConfig(filename=mp3_fname)\n",
    "        synthesizer = speechsdk.SpeechSynthesizer(speech_config=speech_config, audio_config=audio_config)\n",
    "        result = synthesizer.speak_text_async(sentence).get()\n",
    "        if result.reason == speechsdk.ResultReason.SynthesizingAudioCompleted:\n",
    "            print(f\"[OK] 合成完成: {mp3_fname}\")\n",
    "        else:\n",
    "            print(f\"[ERROR] 合成失敗: {sentence}\")\n",
    "            failed_sentences.append((i, sentence))\n",
    "elif tts_server == 'minimax':\n",
    "    load_dotenv()\n",
    "    MINIMAX_SPEECH_KEY = os.environ.get(\"MINIMAX_SPEECH_KEY\")\n",
    "    MINIMAX_URL = \"https://api.minimax.io/v1/t2a_v2?GroupId=1982992498867311582\"\n",
    "    MODEL = config.get(\"minimax_model\", \"speech-02-hd\")\n",
    "    VOICE = config.get(\"minimax_voice\", \"Chinese (Mandarin)_Warm_Bestie\")\n",
    "    EMOTION = config.get(\"minimax_emotion\", \"calm\")\n",
    "    VOL = config.get(\"minimax_vol\", 1.0)\n",
    "    SPEED = config.get(\"minimax_speed\", 1.0)\n",
    "    PITCH = config.get(\"minimax_pitch\", 0)\n",
    "    AUDIO_FORMAT = config.get(\"minimax_audio_format\", \"mp3\")\n",
    "    SAMPLE_RATE = config.get(\"minimax_sample_rate\", 32000)\n",
    "    BITRATE = config.get(\"minimax_bitrate\", 128000)\n",
    "    CHANNEL = config.get(\"minimax_channel\", 1)\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {MINIMAX_SPEECH_KEY}\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    print(f\"[CHECK] MINIMAX voice_id for synthesis: {VOICE}\")\n",
    "    for i, sentence in enumerate(sentences):\n",
    "        fname = os.path.join(subdir, f\"voice_{i}.{AUDIO_FORMAT}\")\n",
    "        if os.path.exists(fname):\n",
    "            overwrite = input(f\"{fname} 已存在，要覆蓋嗎？(y/n): \")\n",
    "            if overwrite.lower() != 'y':\n",
    "                print(f\"跳過 {fname}\")\n",
    "                continue\n",
    "        payload = {\n",
    "            \"model\": MODEL,\n",
    "            \"text\": sentence,\n",
    "            \"voice_setting\": {\n",
    "                \"voice_id\": VOICE,\n",
    "                \"speed\": SPEED,\n",
    "                \"vol\": VOL,\n",
    "                \"pitch\": PITCH,\n",
    "                \"emotion\": EMOTION\n",
    "            },\n",
    "            \"audio_setting\": {\n",
    "                \"sample_rate\": SAMPLE_RATE,\n",
    "                \"bitrate\": BITRATE,\n",
    "                \"format\": AUDIO_FORMAT,\n",
    "                \"channel\": CHANNEL\n",
    "            },\n",
    "            \"output_format\": \"url\",\n",
    "            \"language_boost\": \"auto\",\n",
    "            \"subtitle_enable\": False\n",
    "        }\n",
    "        r = requests.post(MINIMAX_URL, headers=headers, json=payload)\n",
    "        if r.status_code == 200:\n",
    "            data = r.json()\n",
    "            base_resp = data.get(\"base_resp\", {})\n",
    "            if base_resp.get(\"status_code\") == 0:\n",
    "                audio_url = data.get(\"data\", {}).get(\"audio\")\n",
    "                if audio_url:\n",
    "                    r2 = requests.get(audio_url)\n",
    "                    if r2.status_code == 200:\n",
    "                        return r2.content\n",
    "                    else:\n",
    "                        print(\"MINIMAX音檔下載失敗：\", r2.status_code)\n",
    "                else:\n",
    "                    print(\"MINIMAX未取得音檔URL，請檢查API回應！\")\n",
    "            else:\n",
    "                print(\"MINIMAX API錯誤：\", base_resp.get(\"status_msg\"))\n",
    "        else:\n",
    "            print(\"MINIMAX TTS API失敗，狀態碼：\", r.status_code)\n",
    "            print(\"回應：\", r.text[:300])\n",
    "    except Exception as e:\n",
    "        print(\"MINIMAX TTS錯誤：\", e)\n",
    "    return None\n",
    "\n",
    "if tts_server not in ('azure', 'minimax'):\n",
    "    print(f\"[ERROR] 未支援的 TTS server 設定：{tts_server}\")\n",
    "    print(\"請在 config.yaml 設定 tts_server 為 'azure' 或 'minimax'\")\n",
    "else:\n",
    "    success_count = 0\n",
    "    for idx, sentence in enumerate(sentences):\n",
    "        audio_path = os.path.join(voice_dir, f'voice_{idx+1:04d}.mp3')\n",
    "        audio_data = None\n",
    "        if tts_server == 'azure':\n",
    "            audio_data = azure_tts(\n",
    "                sentence,\n",
    "                config.get('azure_voice', 'zh-TW-YunJheNeural'),\n",
    "                config.get('azure_format', 'mp3')\n",
    "            )\n",
    "        elif tts_server == 'minimax':\n",
    "            audio_data = minimax_tts(\n",
    "                sentence,\n",
    "                config.get('minimax_model', 'speech-02-hd'),\n",
    "                config.get('minimax_accent', 'Chinese (Mandarin)'),\n",
    "                config.get('minimax_voice', 'Chinese (Mandarin)_Warm_Bestie'),\n",
    "                config.get('minimax_emotion', 'calm'),\n",
    "                config.get('minimax_speed', 1.0),\n",
    "                config.get('minimax_pitch', 0),\n",
    "                config.get('minimax_vol', 1.0),\n",
    "                config.get('minimax_format', 'mp3'),\n",
    "                config.get('minimax_sample_rate', 32000),\n",
    "                config.get('minimax_bitrate', 128000),\n",
    "                config.get('minimax_channel', 1),\n",
    "                config.get('minimax_language_boost', 'auto'),\n",
    "                config.get('minimax_subtitle_enable', False)\n",
    "            )\n",
    "        if audio_data:\n",
    "            with open(audio_path, \"wb\") as f:\n",
    "                f.write(audio_data)\n",
    "            print(f\"Generated {audio_path}\")\n",
    "            success_count += 1\n",
    "        else:\n",
    "            print(f\"[ERROR] 語音合成失敗：{audio_path}\")\n",
    "\n",
    "    print(f\"TTS synthesis finished. 成功產生 {success_count} 檔案。\")\n",
    "\n",
    "print(\"STEP 4 Complete! TTS synthesis finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6b96a9-2fdb-4712-8342-bb78f115a77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 5: Validate Audio Files and Get Durations\n",
    "from IPython.display import clear_output; clear_output(wait=True)\n",
    "print(\"STEP 5: Validating TTS audio files and getting durations...\")\n",
    "\n",
    "import os\n",
    "import subprocess\n",
    "import yaml\n",
    "\n",
    "# Reload config\n",
    "if os.path.exists('config.yaml'):\n",
    "    with open('config.yaml', encoding='utf-8') as f:\n",
    "        config = yaml.safe_load(f)\n",
    "else:\n",
    "    config = {}\n",
    "\n",
    "subdir = os.getcwd()\n",
    "sentences = config.get('input_text', '').split('\\n') if config.get('input_text') else []\n",
    "\n",
    "valid_sentences = []\n",
    "valid_audio_files = []\n",
    "valid_durations = []\n",
    "\n",
    "for i, sentence in enumerate(sentences):\n",
    "    mp3_fname = os.path.join(subdir, f\"voice_{i}.mp3\")\n",
    "    if os.path.exists(mp3_fname) and os.path.getsize(mp3_fname) > 0:\n",
    "        r = subprocess.run([\n",
    "            \"ffprobe\", \"-v\", \"error\", \"-show_entries\",\n",
    "            \"format=duration\", \"-of\", \"default=noprint_wrappers=1:nokey=1\", mp3_fname\n",
    "        ], capture_output=True)\n",
    "        try:\n",
    "            duration_val = float(r.stdout.decode().strip())\n",
    "            if duration_val > 0.01 and duration_val < 30:\n",
    "                valid_durations.append(duration_val)\n",
    "                valid_audio_files.append(mp3_fname)\n",
    "                valid_sentences.append(sentence)\n",
    "                print(f\"OK: {i}: '{sentence}' ({duration_val:.2f}s)\")\n",
    "            else:\n",
    "                print(f\"Skipped {i}: '{sentence}' - duration {duration_val:.2f}s\")\n",
    "        except Exception as e:\n",
    "            print(f\"[ERROR] ffprobe failed for {mp3_fname}: {e}\")\n",
    "    else:\n",
    "        print(f\"[WARNING] Missing or empty audio file: {mp3_fname}\")\n",
    "\n",
    "print(f\"\\nKept {len(valid_audio_files)} valid audio files and sentences.\")\n",
    "if valid_sentences:\n",
    "    print(f\"✅ Last sentence included: {valid_sentences[-1]}\")\n",
    "print(\"STEP 5 Complete! Audio validation done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e619713-d6ee-47ac-a0f5-3eb2d890f6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 6: Concatenate Audio Files into voice.mp3\n",
    "from IPython.display import clear_output; clear_output(wait=True)\n",
    "print(\"STEP 6: Concatenating TTS audio files into voice.mp3...\")\n",
    "\n",
    "import os\n",
    "import subprocess\n",
    "import yaml\n",
    "\n",
    "# Reload config and get sentences\n",
    "if os.path.exists('config.yaml'):\n",
    "    with open('config.yaml', encoding='utf-8') as f:\n",
    "        config = yaml.safe_load(f)\n",
    "else:\n",
    "    config = {}\n",
    "\n",
    "subdir = os.getcwd()\n",
    "sentences = config.get('input_text', '').split('\\n') if config.get('input_text') else []\n",
    "\n",
    "voice_concat_path = os.path.join(subdir, \"voice.mp3\")\n",
    "audio_files = [os.path.join(subdir, f\"voice_{i}.mp3\") for i in range(len(sentences))]\n",
    "\n",
    "if os.path.exists(voice_concat_path):\n",
    "    overwrite = input(f\"{voice_concat_path} 已存在，要覆蓋嗎？(y/n): \")\n",
    "    if overwrite.lower() != 'y':\n",
    "        print(\"跳過合併語音檔，保留舊檔案。\")\n",
    "        print(\"STEP 6 Complete!\")\n",
    "    else:\n",
    "        print(\"重新合併語音檔。\")\n",
    "        with open(os.path.join(subdir, \"tts_list.txt\"), \"w\", encoding=\"utf-8\") as f:\n",
    "            for af in audio_files:\n",
    "                if os.path.exists(af):\n",
    "                    f.write(f\"file '{af}'\\n\")\n",
    "        cmd = [\n",
    "            \"ffmpeg\", \"-y\",\n",
    "            \"-f\", \"concat\", \"-safe\", \"0\", \"-i\", \"tts_list.txt\",\n",
    "            \"-c\", \"copy\", \"voice.mp3\"\n",
    "        ]\n",
    "        print(\"執行語音合併指令：\", \" \".join(cmd))\n",
    "        subprocess.run(cmd, cwd=subdir)\n",
    "        print(\"STEP 6 Complete!\")\n",
    "else:\n",
    "    print(\"開始合併語音檔。\")\n",
    "    with open(os.path.join(subdir, \"tts_list.txt\"), \"w\", encoding=\"utf-8\") as f:\n",
    "        for af in audio_files:\n",
    "            if os.path.exists(af):\n",
    "                f.write(f\"file '{af}'\\n\")\n",
    "    cmd = [\n",
    "        \"ffmpeg\", \"-y\",\n",
    "        \"-f\", \"concat\", \"-safe\", \"0\", \"-i\", \"tts_list.txt\",\n",
    "        \"-c\", \"copy\", \"voice.mp3\"\n",
    "    ]\n",
    "    print(\"執行語音合併指令：\", \" \".join(cmd))\n",
    "    subprocess.run(cmd, cwd=subdir)\n",
    "    print(\"STEP 6 Complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf5c6ff-03fd-41ef-aa2f-48d803f3df2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 7: Backup Project Data to New Project Directory\n",
    "from IPython.display import clear_output; clear_output(wait=True)\n",
    "print(\"STEP 7: Backing up project files to a new project directory...\")\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import yaml\n",
    "import datetime\n",
    "\n",
    "# Reload config to get latest project title\n",
    "if os.path.exists('config.yaml'):\n",
    "    with open('config.yaml', encoding='utf-8') as f:\n",
    "        config = yaml.safe_load(f)\n",
    "else:\n",
    "    config = {}\n",
    "\n",
    "project_title = config.get('project_title', '新專案')\n",
    "timestamp = datetime.datetime.now().strftime('%Y%m%d')\n",
    "project_dir = os.path.join(os.getcwd(), f\"{timestamp}_{project_title}\")\n",
    "\n",
    "os.makedirs(project_dir, exist_ok=True)\n",
    "\n",
    "files_to_backup = [\n",
    "    config.get('background', 'background.jpg'),\n",
    "    config.get('bgm', 'bgm.mp3'),\n",
    "    config.get('thumbnail', 'thumbnail.jpg'),\n",
    "    config.get('text', 'text.txt'),\n",
    "    'config.yaml',\n",
    "    'voice.mp3',\n",
    "    'voice_bgm.mp3',\n",
    "    'subtitle.srt',\n",
    "    'final.mp4'\n",
    "]\n",
    "for fname in files_to_backup:\n",
    "    src = os.path.join(os.getcwd(), fname)\n",
    "    dst = os.path.join(project_dir, fname)\n",
    "    if os.path.exists(src):\n",
    "        shutil.copy2(src, dst)\n",
    "        print(f\"已備份 {fname} 到 {project_dir}\")\n",
    "    else:\n",
    "        print(f\"找不到 {fname}，略過。\")\n",
    "print(\"STEP 7 Complete! All project files backed up.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4a2c8d-970a-4128-85e9-99411f959e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 8: Generating subtitles (SRT) for the video and YAML for scene planning\n",
    "\n",
    "from IPython.display import clear_output\n",
    "import os\n",
    "import yaml\n",
    "\n",
    "clear_output(wait=True)\n",
    "print(\"STEP 8: Generating subtitles (SRT) for the video...\")\n",
    "\n",
    "# ========== 讀取 Step 5 的結果 ==========\n",
    "# 若在 notebook，valid_sentences, audio_durations 已經存在\n",
    "# 若不存在，則自動重新讀取 voice 檔案和 sentences\n",
    "try:\n",
    "    valid_sentences\n",
    "    audio_durations\n",
    "except NameError:\n",
    "    print(\"audio_durations not found or does not match sentence count, trying to load durations from audio files...\")\n",
    "    # 讀取主文字並切句\n",
    "    if os.path.exists('config.yaml'):\n",
    "        with open('config.yaml', encoding='utf-8') as f:\n",
    "            config = yaml.safe_load(f)\n",
    "    else:\n",
    "        config = {}\n",
    "\n",
    "    text_file = config.get('text', 'text.txt')\n",
    "    if os.path.exists(text_file):\n",
    "        with open(text_file, 'r', encoding='utf-8') as f:\n",
    "            raw_text = f.read().strip()\n",
    "    else:\n",
    "        raw_text = \"\"\n",
    "    from snownlp import SnowNLP\n",
    "    sentences = [s.strip() for s in SnowNLP(raw_text).sentences if s.strip()]\n",
    "\n",
    "    voice_dir = config.get('voice_dir', 'voice')\n",
    "    try:\n",
    "        from pydub import AudioSegment\n",
    "    except ImportError:\n",
    "        raise ImportError(\"需要安裝pydub，請執行 pip install pydub\")\n",
    "    valid_sentences = []\n",
    "    audio_durations = []\n",
    "    for idx, sentence in enumerate(sentences):\n",
    "        audio_file = os.path.join(voice_dir, f'voice_{idx+1:04d}.mp3')\n",
    "        if os.path.exists(audio_file):\n",
    "            audio = AudioSegment.from_file(audio_file)\n",
    "            duration_sec = len(audio) / 1000.0\n",
    "            valid_sentences.append(sentence)\n",
    "            audio_durations.append(duration_sec)\n",
    "\n",
    "# ========== SRT 生成 ==========\n",
    "total_subtitles = len(valid_sentences)\n",
    "print(f\"Total subtitles: {total_subtitles}\")\n",
    "\n",
    "srt_lines = []\n",
    "yaml_data = []\n",
    "\n",
    "start_time = 0.0\n",
    "for idx, (sentence, duration) in enumerate(zip(valid_sentences, audio_durations)):\n",
    "    end_time = start_time + duration\n",
    "    # SRT格式\n",
    "    srt_lines.append(f\"{idx+1}\\n{start_time:.2f} --> {end_time:.2f}\\n{sentence}\\n\")\n",
    "    print(f\"{idx+1}: {start_time:.2f} --> {end_time:.2f} | {sentence}\")\n",
    "    # YAML資料\n",
    "    yaml_data.append({\n",
    "        'index': idx+1,\n",
    "        'start': float(f\"{start_time:.2f}\"),\n",
    "        'end': float(f\"{end_time:.2f}\"),\n",
    "        'text': sentence\n",
    "    })\n",
    "    start_time = end_time\n",
    "\n",
    "with open('subtitle.srt', 'w', encoding='utf-8') as f:\n",
    "    f.write('\\n'.join(srt_lines))\n",
    "print(\"SRT file saved as subtitle.srt.\")\n",
    "\n",
    "with open('subtitle.yaml', 'w', encoding='utf-8') as f:\n",
    "    yaml.safe_dump({'subtitles': yaml_data}, f, allow_unicode=True)\n",
    "print(\"YAML file saved as subtitle.yaml for scene planning.\")\n",
    "\n",
    "print(\"STEP 8 Complete! Subtitles generated for both video editing and scene planning.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49b5653-f9e4-4517-93b4-c2363ad2c6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 8.5: Scene Visual Plan Editor (modular code, notebook cell version with image preview fix)\n",
    "# - Semantic scene split (GPT-3.5)\n",
    "# - DALL·E 3 AI background generation\n",
    "# - Interactive storyboard editor for sentences\n",
    "# - Manual/AI background selection\n",
    "# - Video/audio attachment\n",
    "# - Save full visual plan to YAML\n",
    "\n",
    "import os\n",
    "import openai\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import requests\n",
    "import ipywidgets as widgets\n",
    "import yaml\n",
    "from dotenv import load_dotenv\n",
    "import subprocess\n",
    "import re\n",
    "import functools\n",
    "from IPython.display import display, Image as IPyImage\n",
    "\n",
    "DEFAULT_MAX_SCENES = 4\n",
    "\n",
    "def step8_5_scene_editor(\n",
    "    valid_sentences,\n",
    "    valid_audio_files,\n",
    "    subdir,\n",
    "    main_dir,\n",
    "    config,\n",
    "    ammunition_dir=None,\n",
    "    max_scene=DEFAULT_MAX_SCENES\n",
    "):\n",
    "    print(\"▇▇▇▇ 步驟 8.5 分鏡表編輯器呼叫 ▇▇▇▇\")\n",
    "    print(\"[Debug] valid_sentences[:2]:\", valid_sentences[:2] if isinstance(valid_sentences, list) else valid_sentences)\n",
    "    print(\"[Debug] valid_audio_files[:2]:\", valid_audio_files[:2] if isinstance(valid_audio_files, list) else valid_audio_files)\n",
    "    print(\"[Debug] subdir:\", subdir)\n",
    "    print(\"[Debug] main_dir:\", main_dir)\n",
    "    print(\"[Debug] config:\", config)\n",
    "    print(\"[Debug] ammunition_dir:\", ammunition_dir)\n",
    "    print(\"[Debug] max_scene:\", max_scene)\n",
    "\n",
    "    try:\n",
    "        load_dotenv()\n",
    "        openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "        print(\"[Debug] OPENAI_API_KEY:\", openai_api_key)\n",
    "        openai.api_key = openai_api_key\n",
    "        if not openai_api_key or not openai_api_key.startswith(\"sk-\"):\n",
    "            print(\"[ERROR] OPENAI_API_KEY is not set or invalid!\")\n",
    "            raise RuntimeError(\"OPENAI_API_KEY is not set or invalid. Please check .env or environment variables!\")\n",
    "        if not ammunition_dir:\n",
    "            ammunition_dir = os.path.join(main_dir, \"ammunition\")\n",
    "\n",
    "        print(\"STEP 8.5: Scene Visual Plan Editor\")\n",
    "        print(\"專案名稱:\", config.get(\"project_title\", config.get(\"title\", \"未設定\")))\n",
    "        print(\"Current subdir:\", subdir)\n",
    "        print(\"目前工作目錄：\", os.getcwd())\n",
    "\n",
    "        # --- 1️⃣ Semantic scene split ---\n",
    "        def semantic_scene_split(subtitles, max_scene=4):\n",
    "            print(\"[Debug] semantic_scene_split subtitles[:2]:\", subtitles[:2])\n",
    "            prompt = (\n",
    "                \"請將以下字幕依語意分割為不超過4個場景，每個場景列出起迄句子編號（如：1-5，6-8），只需輸出每個場景的起迄範圍，不需解釋：\\n\"\n",
    "                + \"\\n\".join([f\"{i+1}. {s}\" for i, s in enumerate(subtitles)])\n",
    "            )\n",
    "            print(\"[Debug] GPT Prompt:\", prompt[:80], \"...\")\n",
    "            try:\n",
    "                resp = openai.chat.completions.create(\n",
    "                    model=\"gpt-3.5-turbo\",\n",
    "                    messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "                )\n",
    "                content = resp.choices[0].message.content\n",
    "                print(\"[Debug] GPT分鏡分割 response:\", content)\n",
    "            except Exception as e:\n",
    "                print(\"[ERROR] GPT 分鏡分割失敗:\", type(e), e)\n",
    "                content = \"\"\n",
    "            ranges = []\n",
    "            for line in content.splitlines():\n",
    "                m = re.match(r\"(\\d+)\\s*-\\s*(\\d+)\", line)\n",
    "                if m:\n",
    "                    start = int(m.group(1)) - 1\n",
    "                    end = int(m.group(2))\n",
    "                    ranges.append((start, end))\n",
    "            if not ranges:\n",
    "                print(\"[WARNING] GPT未能分割分鏡，使用預設範圍\")\n",
    "                ranges = [(0, len(subtitles))]\n",
    "            return ranges[:max_scene]\n",
    "\n",
    "        scene_ranges = semantic_scene_split(valid_sentences, max_scene)\n",
    "        print(\"[Debug] scene_ranges:\", scene_ranges)\n",
    "        scene_images = [None] * len(scene_ranges)\n",
    "        scene_img_names = [None] * len(scene_ranges)\n",
    "\n",
    "        # --- 2️⃣ UI and file lists ---\n",
    "        try:\n",
    "            all_files = os.listdir(ammunition_dir)\n",
    "            print(\"[Debug] all_files:\", all_files)\n",
    "        except Exception as e:\n",
    "            print(f\"[ERROR] Failed to list ammunition_dir: {e}\")\n",
    "            all_files = []\n",
    "\n",
    "        image_files = [f for f in all_files if f.lower().endswith(('.jpg', '.png'))]\n",
    "        video_files = [f for f in all_files if f.lower().endswith(('.mp4', '.mov', '.avi'))]\n",
    "        music_files = [f for f in all_files if f.lower().endswith(('.mp3', '.wav'))]\n",
    "        print(\"[Debug] image_files:\", image_files)\n",
    "        print(\"[Debug] video_files:\", video_files)\n",
    "        print(\"[Debug] music_files:\", music_files)\n",
    "\n",
    "        video_info = []\n",
    "        for vf in video_files:\n",
    "            path = os.path.join(ammunition_dir, vf)\n",
    "            result = subprocess.run([\n",
    "                \"ffprobe\", \"-v\", \"error\", \"-show_entries\",\n",
    "                \"format=duration\", \"-of\", \"default=noprint_wrappers=1:nokey=1\", path\n",
    "            ], capture_output=True)\n",
    "            try:\n",
    "                dur = float(result.stdout.decode().strip())\n",
    "            except Exception:\n",
    "                dur = None\n",
    "            video_info.append((vf, dur))\n",
    "        video_options = [\"(無)\"] + [f\"{fn} ({d:.2f}s)\" if d else fn for fn, d in video_info]\n",
    "        video_map = {f\"{fn} ({d:.2f}s)\": fn for fn, d in video_info if d}\n",
    "        image_options = [\"(無)\"] + image_files\n",
    "        print(\"[Debug] video_options:\", video_options)\n",
    "        print(\"[Debug] video_map:\", video_map)\n",
    "\n",
    "        audio_durations = [None] * len(valid_sentences)\n",
    "        for i in range(len(valid_sentences)):\n",
    "            af = valid_audio_files[i] if i < len(valid_audio_files) else None\n",
    "            if af and os.path.exists(af):\n",
    "                result = subprocess.run([\n",
    "                    \"ffprobe\", \"-v\", \"error\", \"-show_entries\",\n",
    "                    \"format=duration\", \"-of\", \"default=noprint_wrappers=1:nokey=1\", af\n",
    "                ], capture_output=True)\n",
    "                try:\n",
    "                    audio_durations[i] = float(result.stdout.decode().strip())\n",
    "                except Exception:\n",
    "                    audio_durations[i] = None\n",
    "        accum_durations = []\n",
    "        running_total = 0.0\n",
    "        for d in audio_durations:\n",
    "            running_total += d if d else 0\n",
    "            accum_durations.append(running_total)\n",
    "        print(\"[Debug] audio_durations:\", audio_durations)\n",
    "        print(\"[Debug] accum_durations:\", accum_durations)\n",
    "\n",
    "        # --- 3️⃣ UI for sentences ---\n",
    "        sentence_labels = []\n",
    "        bg_selectors = []\n",
    "        vid_selectors = []\n",
    "        bg_preview_btns = []\n",
    "\n",
    "        for i, sentence in enumerate(valid_sentences):\n",
    "            aud_dur = audio_durations[i] if i < len(audio_durations) and audio_durations[i] else 0\n",
    "            accum_dur = accum_durations[i] if i < len(accum_durations) else 0\n",
    "            label_txt = f\"{i+1}. {sentence[:40]} (audio: {aud_dur:.2f}s, total: {accum_dur:.2f}s)\"\n",
    "            sentence_label = widgets.Label(label_txt)\n",
    "            bg_default = \"(無)\"\n",
    "            bg_dd_options = [\"(無)\"] + image_files\n",
    "            bg_dd = widgets.Dropdown(options=bg_dd_options, value=bg_default, description=\"\")\n",
    "            vid_dd = widgets.Dropdown(options=video_options, value=\"(無)\", description=\"\")\n",
    "            sentence_labels.append(sentence_label)\n",
    "            bg_selectors.append(bg_dd)\n",
    "            vid_selectors.append(vid_dd)\n",
    "            # Preview button\n",
    "            img_preview_widget = widgets.Output()\n",
    "            def preview_fun(img_dd, img_preview_widget):\n",
    "                def show(_):\n",
    "                    img_name = img_dd.value\n",
    "                    if img_name != \"(無)\":\n",
    "                        img_path = os.path.join(subdir, img_name)\n",
    "                        if not os.path.exists(img_path):\n",
    "                            img_path = os.path.join(ammunition_dir, img_name)\n",
    "                        if os.path.exists(img_path):\n",
    "                            img_preview_widget.clear_output()\n",
    "                            with img_preview_widget:\n",
    "                                display(IPyImage(filename=img_path))\n",
    "                return show\n",
    "            preview_btn = widgets.Button(description=\"預覽背景\")\n",
    "            preview_btn.on_click(preview_fun(bg_dd, img_preview_widget))\n",
    "            bg_preview_btns.append(widgets.VBox([preview_btn, img_preview_widget]))\n",
    "\n",
    "        col1_title = widgets.HTML(\"<b>句子 / 時間</b>\")\n",
    "        col2_title = widgets.HTML(\"<b>背景圖片</b>\")\n",
    "        col3_title = widgets.HTML(\"<b>背景預覽</b>\")\n",
    "        col4_title = widgets.HTML(\"<b>影片剪輯</b>\")\n",
    "\n",
    "        sentence_labels_col = widgets.VBox([col1_title] + sentence_labels)\n",
    "        bg_selectors_col = widgets.VBox([col2_title] + bg_selectors)\n",
    "        bg_preview_col  = widgets.VBox([col3_title] + bg_preview_btns)\n",
    "        vid_selectors_col = widgets.VBox([col4_title] + vid_selectors)\n",
    "        table_ui = widgets.HBox([sentence_labels_col, bg_selectors_col, bg_preview_col, vid_selectors_col])\n",
    "\n",
    "        instructions = widgets.HTML(\"\"\"\n",
    "        <b>分鏡表編輯器（語意分場景AI背景/手動選檔 + 分句細緻分鏡表 + 預覽功能）</b><br>\n",
    "        上方：場景分段字幕、AI背景生成/手動選檔（產生/選擇後自動分配背景，分鏡表即時更新）<br>\n",
    "        下方：分句分鏡表可手動調整背景、影片等（預設已依場景分配背景）<br>\n",
    "        儲存時背景空白自動沿用上一句設定。\n",
    "        \"\"\")\n",
    "        print(\"[Debug] UI 準備顯示\")\n",
    "        display(instructions, table_ui)\n",
    "\n",
    "        # --- 4️⃣ Scene UI, AI image generation and manual selection ---\n",
    "        def sanitize_title(title):\n",
    "            return re.sub(r\"[^\\u4e00-\\u9fa5A-Za-z0-9]\", \"\", title)[:10] or \"scene\"\n",
    "\n",
    "        def dalle3_generate(prompt, idx, seg_sentences, size=\"1792x1024\"):\n",
    "            scene_title = sanitize_title(seg_sentences[0]) if seg_sentences else f\"scene{idx+1}\"\n",
    "            fname = os.path.join(subdir, f\"ai_scene_{idx+1}_{scene_title}.jpg\")\n",
    "            print(f\"[Debug] 呼叫DALL·E 生成場景{idx+1}: {scene_title}\")\n",
    "            try:\n",
    "                response = openai.images.generate(\n",
    "                    model=\"dall-e-3\",\n",
    "                    prompt=prompt,\n",
    "                    size=size,\n",
    "                    n=1,\n",
    "                    quality=\"standard\"\n",
    "                )\n",
    "                print(\"[Debug] DALL·E response url:\", response.data[0].url)\n",
    "                url = response.data[0].url\n",
    "                imgdata = requests.get(url).content\n",
    "                img = Image.open(BytesIO(imgdata))\n",
    "                img_resized = img.resize((1920, 1080), resample=Image.LANCZOS)\n",
    "                img_resized.save(fname, format=\"JPEG\")\n",
    "                print(f\"[Debug] AI場景圖片已儲存：{fname}\")\n",
    "                return fname\n",
    "            except Exception as e:\n",
    "                print(\"[ERROR] DALL·E圖片生成失敗:\", e)\n",
    "                raise\n",
    "\n",
    "        scene_widgets = []\n",
    "        for idx, (start, end) in enumerate(scene_ranges):\n",
    "            seg_sentences = valid_sentences[start:end]\n",
    "            seg_text = \"\\n\".join([f\"{i+1}. {s}\" for i, s in enumerate(seg_sentences)])\n",
    "            prompt = f\"Minimalist, modern, unique illustration for a YouTube thumbnail. Scene {idx+1}: {seg_text}\"\n",
    "\n",
    "            label = widgets.HTML(f\"<b>場景{idx+1} 字幕:</b><br><pre>{seg_text}</pre>\")\n",
    "            img_preview = widgets.Output()\n",
    "            img_path_label = widgets.Label(\"尚未選取圖片\")\n",
    "            select_img_dd = widgets.Dropdown(options=[\"(請選擇)\"] + image_files, value=\"(請選擇)\", description=\"\")\n",
    "\n",
    "            def on_gen_clicked(b, idx=idx, prompt=prompt, seg_sentences=seg_sentences, start=start, end=end, img_preview=img_preview):\n",
    "                print(f\"[Debug] 產生 AI 背景 (idx={idx})\")\n",
    "                try:\n",
    "                    fname = dalle3_generate(prompt, idx, seg_sentences)\n",
    "                    scene_images[idx] = fname\n",
    "                    scene_img_names[idx] = os.path.basename(fname)\n",
    "                    img_preview.clear_output()\n",
    "                    img_path_label.value = f\"AI生成：{os.path.basename(fname)}\"\n",
    "                    with img_preview:\n",
    "                        display(IPyImage(filename=fname))\n",
    "                    for i in range(start, end):\n",
    "                        bg_selectors[i].value = os.path.basename(fname)\n",
    "                except Exception as e:\n",
    "                    img_preview.clear_output()\n",
    "                    img_path_label.value = f\"生成失敗: {e}\"\n",
    "                    print(f\"[ERROR] 產生AI圖片失敗 idx={idx}: {e}\")\n",
    "\n",
    "            def on_select_img_change(change, idx=idx, start=start, end=end, img_preview=img_preview):\n",
    "                print(f\"[Debug] 選擇手動背景 idx={idx}\")\n",
    "                if change[\"name\"] == \"value\" and change[\"new\"] != \"(請選擇)\":\n",
    "                    chosen = change[\"new\"]\n",
    "                    scene_images[idx] = os.path.join(ammunition_dir, chosen)\n",
    "                    scene_img_names[idx] = chosen\n",
    "                    img_preview.clear_output()\n",
    "                    img_path_label.value = f\"使用檔案：{chosen}\"\n",
    "                    img_path = os.path.join(ammunition_dir, chosen)\n",
    "                    if os.path.exists(img_path):\n",
    "                        with img_preview:\n",
    "                            display(IPyImage(filename=img_path))\n",
    "                    for i in range(start, end):\n",
    "                        bg_selectors[i].value = chosen\n",
    "\n",
    "            select_img_dd.observe(lambda change, idx=idx, start=start, end=end, img_preview=img_preview: on_select_img_change(change, idx, start, end, img_preview), names=\"value\")\n",
    "            btn_gen = widgets.Button(description=\"重新產生\", button_style=\"danger\")\n",
    "            btn_gen.on_click(functools.partial(on_gen_clicked, idx=idx, prompt=prompt, seg_sentences=seg_sentences, start=start, end=end, img_preview=img_preview))\n",
    "\n",
    "            seg_box = widgets.VBox([\n",
    "                label,\n",
    "                widgets.HBox([widgets.Label(\"沿用圖片：\"), select_img_dd]),\n",
    "                btn_gen,\n",
    "                img_path_label,\n",
    "                img_preview\n",
    "            ])\n",
    "            scene_widgets.append(seg_box)\n",
    "\n",
    "        scene_ui = widgets.VBox(scene_widgets)\n",
    "        print(\"[Debug] 分鏡場景UI顯示\")\n",
    "        display(scene_ui)\n",
    "\n",
    "        # --- 5️⃣ Save visual plan ---\n",
    "        save_btn = widgets.Button(description=\"儲存分鏡表\", button_style=\"success\")\n",
    "        output = widgets.Output()\n",
    "\n",
    "        def get_duration(path):\n",
    "            print(f\"[Debug] get_duration called for path: {path}\")\n",
    "            if not os.path.exists(path):\n",
    "                print(f\"[Debug] 路徑不存在: {path}\")\n",
    "                return None\n",
    "            result = subprocess.run([\n",
    "                \"ffprobe\", \"-v\", \"error\", \"-show_entries\",\n",
    "                \"format=duration\", \"-of\", \"default=noprint_wrappers=1:nokey=1\", path\n",
    "            ], capture_output=True)\n",
    "            try:\n",
    "                dur = float(result.stdout.decode().strip())\n",
    "                print(f\"[Debug] 讀取到 duration: {dur}\")\n",
    "                return dur\n",
    "            except Exception as e:\n",
    "                print(f\"[ERROR] get_duration fail: {e}\")\n",
    "                return None\n",
    "\n",
    "        def save_plan(b):\n",
    "            print(\"[Debug] 儲存分鏡表開始\")\n",
    "            with output:\n",
    "                output.clear_output()\n",
    "                visual_plan = []\n",
    "                warnings = []\n",
    "                bg_list = []\n",
    "                for i, bg_dd in enumerate(bg_selectors):\n",
    "                    val = bg_dd.value\n",
    "                    if val and val != \"(無)\":\n",
    "                        f1 = os.path.join(subdir, val)\n",
    "                        f2 = os.path.join(ammunition_dir, val)\n",
    "                        bg_path = f1 if os.path.exists(f1) else f2 if os.path.exists(f2) else val\n",
    "                        bg_list.append(bg_path)\n",
    "                    else:\n",
    "                        bg_list.append(None)\n",
    "                last_bg = None\n",
    "                for i in range(len(bg_list)):\n",
    "                    if bg_list[i] is None and last_bg is not None:\n",
    "                        bg_list[i] = last_bg\n",
    "                    elif bg_list[i] is not None:\n",
    "                        last_bg = bg_list[i]\n",
    "                for i, sentence in enumerate(valid_sentences):\n",
    "                    bg = bg_list[i]\n",
    "                    vid_label = vid_selectors[i].value\n",
    "                    vid = None\n",
    "                    vid_dur = None\n",
    "                    if vid_label != \"(無)\":\n",
    "                        if vid_label in video_map:\n",
    "                            vid = video_map[vid_label]\n",
    "                            vid_dur = get_duration(os.path.join(ammunition_dir, vid))\n",
    "                        else:\n",
    "                            vid = vid_label.split(\" (\")[0]\n",
    "                            vid_dur = get_duration(os.path.join(ammunition_dir, vid))\n",
    "                    audio_fname = valid_audio_files[i]\n",
    "                    audio_dur = audio_durations[i] if i < len(audio_durations) and audio_durations[i] else 0\n",
    "                    accum_dur = accum_durations[i] if i < len(accum_durations) else 0\n",
    "                    if vid and vid_dur and audio_dur and abs(vid_dur - audio_dur) > 1.0:\n",
    "                        warnings.append(f\"⚠️ 句{i+1}影片({vid_dur:.2f}s)與語音({audio_dur:.2f}s)時長不符。\")\n",
    "                    visual_plan.append({\n",
    "                        \"sentence_idx\": i,\n",
    "                        \"sentence\": sentence,\n",
    "                        \"audio_file\": audio_fname,\n",
    "                        \"audio_duration\": audio_dur,\n",
    "                        \"accum_duration\": accum_dur,\n",
    "                        \"background\": bg,\n",
    "                        \"video_clip\": vid,\n",
    "                        \"video_duration\": vid_dur\n",
    "                    })\n",
    "                visual_plan_path = os.path.join(subdir, \"visual_plan.yaml\")\n",
    "                with open(visual_plan_path, \"w\", encoding=\"utf-8\") as f:\n",
    "                    yaml.safe_dump(visual_plan, f, allow_unicode=True)\n",
    "                print(f\"分鏡表已儲存至 {visual_plan_path}\")\n",
    "                if warnings:\n",
    "                    print(\"\\n\".join(warnings))\n",
    "                print(\"前3項：\")\n",
    "                for vp in visual_plan[:3]:\n",
    "                    print(vp)\n",
    "\n",
    "        save_btn.on_click(save_plan)\n",
    "        print(\"[Debug] 儲存分鏡表按鈕顯示\")\n",
    "        display(save_btn, output)\n",
    "        print(\"=\"*40)\n",
    "        print(f\"專案名稱: {config.get('project_title', config.get('title', '未設定'))}\")\n",
    "        print(f\"Current subdir: {subdir}\")\n",
    "        print(f\"目前工作目錄：{os.getcwd()}\")\n",
    "        print(\"=\"*40)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"▇▇▇▇ [ERROR/FATAL] step8_5_scene_editor Exception:\", type(e), e)\n",
    "        import traceback; traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd92cd6-5134-4236-9709-a36bd13fa573",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 9: Mix voice.mp3 and BGM into voice_bgm.mp3\n",
    "from IPython.display import clear_output; clear_output(wait=True)\n",
    "print(\"STEP 9: Mixing voice.mp3 and BGM into voice_bgm.mp3...\")\n",
    "\n",
    "import os\n",
    "import yaml\n",
    "import subprocess\n",
    "\n",
    "# Reload config for BGM info\n",
    "if os.path.exists('config.yaml'):\n",
    "    with open('config.yaml', encoding='utf-8') as f:\n",
    "        config = yaml.safe_load(f)\n",
    "else:\n",
    "    config = {}\n",
    "\n",
    "subdir = os.getcwd()\n",
    "voice_path = os.path.join(subdir, \"voice.mp3\")\n",
    "bgm_path = os.path.join(subdir, config.get('bgm', 'bgm.mp3'))\n",
    "output_path = os.path.join(subdir, \"voice_bgm.mp3\")\n",
    "bgm_volume = config.get('bgm_volume', 0.3)\n",
    "\n",
    "if not os.path.exists(voice_path):\n",
    "    print(f\"[ERROR] 找不到語音檔: {voice_path}\")\n",
    "elif not os.path.exists(bgm_path):\n",
    "    print(f\"[ERROR] 找不到背景音樂檔: {bgm_path}\")\n",
    "elif os.path.exists(output_path):\n",
    "    overwrite = input(f\"{output_path} 已存在，要覆蓋嗎？(y/n): \")\n",
    "    if overwrite.lower() != 'y':\n",
    "        print(\"跳過混音，保留舊檔案。\")\n",
    "        print(\"STEP 9 Complete!\")\n",
    "    else:\n",
    "        print(\"重新混音 voice.mp3 和 BGM。\")\n",
    "        cmd = [\n",
    "            \"ffmpeg\", \"-y\",\n",
    "            \"-i\", voice_path,\n",
    "            \"-i\", bgm_path,\n",
    "            \"-filter_complex\", f\"[1:a]volume={bgm_volume}[bgm];[0:a][bgm]amix=inputs=2:duration=first:dropout_transition=2\",\n",
    "            \"-c:a\", \"mp3\", output_path\n",
    "        ]\n",
    "        print(\"執行混音指令：\", \" \".join(cmd))\n",
    "        subprocess.run(cmd, cwd=subdir)\n",
    "        print(\"STEP 9 Complete!\")\n",
    "else:\n",
    "    print(\"開始混音 voice.mp3 和 BGM。\")\n",
    "    cmd = [\n",
    "        \"ffmpeg\", \"-y\",\n",
    "        \"-i\", voice_path,\n",
    "        \"-i\", bgm_path,\n",
    "        \"-filter_complex\", f\"[1:a]volume={bgm_volume}[bgm];[0:a][bgm]amix=inputs=2:duration=first:dropout_transition=2\",\n",
    "        \"-c:a\", \"mp3\", output_path\n",
    "    ]\n",
    "    print(\"執行混音指令：\", \" \".join(cmd))\n",
    "    subprocess.run(cmd, cwd=subdir)\n",
    "    print(\"STEP 9 Complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9c3a75-08fc-45d3-9dcf-ecf741b41154",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 10: Generate final video (final.mp4) with background image, mixed audio, and subtitles\n",
    "from IPython.display import clear_output; clear_output(wait=True)\n",
    "print(\"STEP 10: Generating final video (final.mp4) using background, voice_bgm.mp3, and subtitle.srt...\")\n",
    "\n",
    "import os\n",
    "import yaml\n",
    "import subprocess\n",
    "\n",
    "# Reload config\n",
    "if os.path.exists('config.yaml'):\n",
    "    with open('config.yaml', encoding='utf-8') as f:\n",
    "        config = yaml.safe_load(f)\n",
    "else:\n",
    "    config = {}\n",
    "\n",
    "subdir = os.getcwd()\n",
    "bg_image = os.path.join(subdir, config.get('background', 'background.jpg'))\n",
    "audio_file = os.path.join(subdir, \"voice_bgm.mp3\")\n",
    "subtitle_file = os.path.join(subdir, \"subtitle.srt\")\n",
    "video_resolution = config.get('video_resolution', '1920,1080')\n",
    "output_file = os.path.join(subdir, \"final.mp4\")\n",
    "\n",
    "if not os.path.exists(bg_image):\n",
    "    print(f\"[ERROR] 找不到背景圖片: {bg_image}\")\n",
    "elif not os.path.exists(audio_file):\n",
    "    print(f\"[ERROR] 找不到混音語音檔: {audio_file}\")\n",
    "elif not os.path.exists(subtitle_file):\n",
    "    print(f\"[ERROR] 找不到字幕檔: {subtitle_file}\")\n",
    "elif os.path.exists(output_file):\n",
    "    overwrite = input(f\"{output_file} 已存在，要覆蓋嗎？(y/n): \")\n",
    "    if overwrite.lower() != 'y':\n",
    "        print(\"跳過影片產生，保留舊檔案。\")\n",
    "        print(\"STEP 10 Complete!\")\n",
    "    else:\n",
    "        print(\"重新產生影片。\")\n",
    "        cmd = [\n",
    "            \"ffmpeg\", \"-y\",\n",
    "            \"-loop\", \"1\",\n",
    "            \"-i\", bg_image,\n",
    "            \"-i\", audio_file,\n",
    "            \"-vf\", f\"subtitles={subtitle_file},scale={video_resolution}\",\n",
    "            \"-c:v\", \"libx264\", \"-tune\", \"stillimage\",\n",
    "            \"-c:a\", \"aac\",\n",
    "            \"-b:a\", \"192k\",\n",
    "            \"-pix_fmt\", \"yuv420p\",\n",
    "            \"-shortest\",\n",
    "            output_file\n",
    "        ]\n",
    "        print(\"執行影片產生指令：\", \" \".join(cmd))\n",
    "        subprocess.run(cmd, cwd=subdir)\n",
    "        print(f\"影片檔已產生: {output_file}\")\n",
    "        print(\"STEP 10 Complete!\")\n",
    "else:\n",
    "    print(\"開始產生影片。\")\n",
    "    cmd = [\n",
    "        \"ffmpeg\", \"-y\",\n",
    "        \"-loop\", \"1\",\n",
    "        \"-i\", bg_image,\n",
    "        \"-i\", audio_file,\n",
    "        \"-vf\", f\"subtitles={subtitle_file},scale={video_resolution}\",\n",
    "        \"-c:v\", \"libx264\", \"-tune\", \"stillimage\",\n",
    "        \"-c:a\", \"aac\",\n",
    "        \"-b:a\", \"192k\",\n",
    "        \"-pix_fmt\", \"yuv420p\",\n",
    "        \"-shortest\",\n",
    "        output_file\n",
    "    ]\n",
    "    print(\"執行影片產生指令：\", \" \".join(cmd))\n",
    "    subprocess.run(cmd, cwd=subdir)\n",
    "    print(f\"影片檔已產生: {output_file}\")\n",
    "    print(\"STEP 10 Complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88bf0275-badc-4453-8c6a-2035accba037",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 11: Generate YouTube Thumbnail (thumbnail.jpg)\n",
    "from IPython.display import clear_output; clear_output(wait=True)\n",
    "print(\"STEP 11: Creating YouTube thumbnail image (thumbnail.jpg)...\")\n",
    "\n",
    "import os\n",
    "import yaml\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "\n",
    "# Reload config\n",
    "if os.path.exists('config.yaml'):\n",
    "    with open('config.yaml', encoding='utf-8') as f:\n",
    "        config = yaml.safe_load(f)\n",
    "else:\n",
    "    config = {}\n",
    "\n",
    "subdir = os.getcwd()\n",
    "thumbnail_path = os.path.join(subdir, config.get('thumbnail', 'thumbnail.jpg'))\n",
    "background_path = os.path.join(subdir, config.get('background', 'background.jpg'))\n",
    "project_title = config.get('project_title', '新專案')\n",
    "subtitle_font = os.path.join(subdir, config.get('subtitle_font', 'NotoSansCJKtc-Regular.otf'))\n",
    "subtitle_fontsize = config.get('subtitle_fontsize', 60)\n",
    "\n",
    "if os.path.exists(thumbnail_path):\n",
    "    overwrite = input(f\"{thumbnail_path} 已存在，要覆蓋嗎？(y/n): \")\n",
    "    if overwrite.lower() != 'y':\n",
    "        print(\"跳過縮圖產生，保留舊檔案。\")\n",
    "        print(\"STEP 11 Complete!\")\n",
    "    else:\n",
    "        print(\"重新產生縮圖。\")\n",
    "        try:\n",
    "            base_img = Image.open(background_path).convert(\"RGB\")\n",
    "            draw = ImageDraw.Draw(base_img)\n",
    "            font = ImageFont.truetype(subtitle_font, subtitle_fontsize)\n",
    "            w, h = base_img.size\n",
    "            text = project_title\n",
    "            text_w, text_h = draw.textsize(text, font=font)\n",
    "            draw.text(((w - text_w) / 2, h * 0.85), text, font=font, fill=\"white\")\n",
    "            base_img.save(thumbnail_path)\n",
    "            print(f\"縮圖已產生: {thumbnail_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"[ERROR] Failed to create thumbnail: {e}\")\n",
    "        print(\"STEP 11 Complete!\")\n",
    "else:\n",
    "    print(\"開始產生縮圖。\")\n",
    "    try:\n",
    "        base_img = Image.open(background_path).convert(\"RGB\")\n",
    "        draw = ImageDraw.Draw(base_img)\n",
    "        font = ImageFont.truetype(subtitle_font, subtitle_fontsize)\n",
    "        w, h = base_img.size\n",
    "        text = project_title\n",
    "        text_w, text_h = draw.textsize(text, font=font)\n",
    "        draw.text(((w - text_w) / 2, h * 0.85), text, font=font, fill=\"white\")\n",
    "        base_img.save(thumbnail_path)\n",
    "        print(f\"縮圖已產生: {thumbnail_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Failed to create thumbnail: {e}\")\n",
    "    print(\"STEP 11 Complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf4cd6f-2fbe-4b2e-87db-3c6601334787",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 12: Prepare YouTube Export Info (title, description, files)\n",
    "from IPython.display import clear_output; clear_output(wait=True)\n",
    "print(\"STEP 12: Preparing YouTube export info (title, description, files)...\")\n",
    "\n",
    "import os\n",
    "import yaml\n",
    "\n",
    "# Reload config\n",
    "if os.path.exists('config.yaml'):\n",
    "    with open('config.yaml', encoding='utf-8') as f:\n",
    "        config = yaml.safe_load(f)\n",
    "else:\n",
    "    config = {}\n",
    "\n",
    "subdir = os.getcwd()\n",
    "project_title = config.get('project_title', '新專案')\n",
    "project_author = config.get('project_author', '')\n",
    "attribution = config.get('attribution', '')\n",
    "thumbnail_path = os.path.join(subdir, config.get('thumbnail', 'thumbnail.jpg'))\n",
    "video_path = os.path.join(subdir, \"final.mp4\")\n",
    "description_path = os.path.join(subdir, \"youtube_description.txt\")\n",
    "\n",
    "# Build YouTube description text\n",
    "description_lines = [\n",
    "    f\"標題: {project_title}\",\n",
    "    f\"作者: {project_author}\",\n",
    "    \"\",\n",
    "    \"說明：\",\n",
    "    attribution,\n",
    "    \"\",\n",
    "    \"（自動生成，請在上傳前自行補充/修改）\"\n",
    "]\n",
    "description_text = '\\n'.join(description_lines)\n",
    "\n",
    "with open(description_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(description_text)\n",
    "print(f\"已產生 YouTube 說明檔: {description_path}\")\n",
    "\n",
    "print(\"請用以下檔案進行 YouTube 上傳：\")\n",
    "print(f\"影片檔: {video_path}\")\n",
    "print(f\"縮圖檔: {thumbnail_path}\")\n",
    "print(f\"說明檔: {description_path}\")\n",
    "\n",
    "print(\"STEP 12 Complete! YouTube export info is ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a1ce18-3a6b-4068-9f85-211d2de1dfb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c14f15-70ce-423d-a54a-a1a1de1c836f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2a0363-5797-451b-9dcc-d9b4cc9c2716",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d239dcd-4648-4597-9fd0-38701c23e4ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4257dc4-fd7e-4b1a-8bf1-375f5dfa8b92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4f73d762",
   "metadata": {},
   "source": [
    "# TTS Video Project Pipeline\n",
    "This notebook covers all steps from input text, TTS voice synthesis, subtitle generation, audio/video concatenation, image processing, and final export for YouTube."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f84941-99dd-488f-8895-9a1d573e282b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install azure-cognitiveservices-speech pysubs2 pillow snownlp python-dotenv tqdm pyyaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6527831b-0101-470b-90f5-dd72c34bff75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: STEP 0 專案資料/初始化\n",
    "print(\"STEP 0: 初始化與專案資料\")\n",
    "import os\n",
    "import yaml\n",
    "\n",
    "main_dir = os.getcwd()\n",
    "config_path = os.path.join(main_dir, \"config.yaml\")\n",
    "with open(config_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "# 檢查背景圖\n",
    "bg_img = os.path.join(main_dir, config.get('background', 'background.jpg'))\n",
    "if not os.path.exists(bg_img):\n",
    "    print(f\"請將背景圖 {config.get('background', 'background.jpg')} 放到主工作區！\")\n",
    "else:\n",
    "    print(f\"背景圖已在主工作區：{bg_img}\")\n",
    "\n",
    "# 檢查配樂\n",
    "bgm_file = os.path.join(main_dir, config.get('bgm', 'bgm.mp3'))\n",
    "if not os.path.exists(bgm_file):\n",
    "    print(f\"請將背景音樂 {config.get('bgm', 'bgm.mp3')} 放到主工作區！\")\n",
    "else:\n",
    "    print(f\"背景音樂已在主工作區：{bgm_file}\")\n",
    "\n",
    "# 其他初始化\n",
    "print(\"主工作區：\", main_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d23932-40a1-464e-acce-e5581a8aaec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: STEP 1 TTS語音合成\n",
    "print(\"STEP 1: TTS語音合成\")\n",
    "# 假設 sentences 已準備好\n",
    "import glob\n",
    "\n",
    "sentences = [...]  # 請根據你的資料來源調整\n",
    "tts_files = []\n",
    "for i, text in enumerate(sentences):\n",
    "    tts_path = os.path.join(main_dir, f\"voice_{i}.mp3\")\n",
    "    if not os.path.exists(tts_path):\n",
    "        # 請填入你自己的 TTS 合成程序\n",
    "        print(f\"合成語音：voice_{i}.mp3\")\n",
    "        # tts_synthesize(text, tts_path)\n",
    "    else:\n",
    "        print(f\"語音檔已存在：voice_{i}.mp3\")\n",
    "    tts_files.append(tts_path)\n",
    "print(\"TTS語音合成完畢，共產生\", len(tts_files), \"個語音檔\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54166782-7dab-4c65-96aa-0a95fc2cb57b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "093e4aec-d0a8-4fbb-b119-be536933c018",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a902f7-d77d-4dec-a104-8abdd91c1fd4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e01f03-072c-42b8-95d2-c8ff128824ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b521fcd9-5140-414c-b660-5e4d673b1360",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Set main working directory\n",
    "main_dir = r\"C:\\Users\\flyre\\mynotebooks\"\n",
    "os.chdir(main_dir)\n",
    "subdir = main_dir\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "AZURE_SPEECH_KEY = os.environ.get(\"AZURE_SPEECH_KEY\")\n",
    "AZURE_SPEECH_REGION = os.environ.get(\"AZURE_SPEECH_REGION\")\n",
    "MINIMAX_SPEECH_KEY = os.environ.get(\"MINIMAX_SPEECH_KEY\")\n",
    "if not AZURE_SPEECH_KEY or not AZURE_SPEECH_REGION or not MINIMAX_SPEECH_KEY:\n",
    "    raise ValueError(\"Missing AZURE_SPEECH_KEY or AZURE_SPEECH_REGION or MINIMAX_SPEECH_KEY in .env file!\")\n",
    "\n",
    "# Load config.yaml if it exists, otherwise use empty config\n",
    "if os.path.exists('config.yaml'):\n",
    "    with open('config.yaml', encoding='utf-8') as f:\n",
    "        config = yaml.safe_load(f)\n",
    "else:\n",
    "    config = {}\n",
    "\n",
    "print(\"=\"*40)\n",
    "print(f\"專案名稱: {config.get('project_title', config.get('title', '未設定'))}\")\n",
    "print(f\"Current subdir: {subdir}\")\n",
    "print(f\"目前工作目錄：{os.getcwd()}\")\n",
    "print(\"=\"*40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43bf6094-7d2b-4e73-92c4-7cabaf751d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 3\n",
    "print(\"專案名稱:\", config.get(\"project_title\", config.get(\"title\", \"未設定\")))\n",
    "print(\"Current subdir:\", subdir)\n",
    "print(\"目前工作目錄：\", os.getcwd())\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output, Audio\n",
    "import yaml\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import requests\n",
    "import tempfile\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "label_style = {'description_width': '120px'}\n",
    "wide_layout = widgets.Layout(width='1100px')\n",
    "wide_textarea_layout = widgets.Layout(width='1100px', height='250px')\n",
    "wide_preview_textarea_layout = widgets.Layout(width='1100px', height='125px')\n",
    "\n",
    "# Azure voices\n",
    "azure_voice_options = [\n",
    "    'zh-TW-YunJheNeural', 'zh-TW-HsiaoChenNeural', 'zh-CN-YunxiNeural',\n",
    "    'en-US-JennyNeural', 'en-US-AriaNeural', 'en-US-GuyNeural',\n",
    "    'ja-JP-NanamiNeural', 'ja-JP-KeitaNeural'\n",
    "]\n",
    "\n",
    "# MINIMAX accents and voices\n",
    "minimax_accent_options = [\n",
    "    ('中文-普通話', 'Chinese (Mandarin)'),\n",
    "    ('英文', 'English'),\n",
    "    ('日文', 'Japanese')\n",
    "]\n",
    "minimax_voice_dict = {\n",
    "    'Chinese (Mandarin)': [\n",
    "        'Chinese (Mandarin)_Warm_Bestie',\n",
    "        'Chinese (Mandarin)_Lyrical_Voice',\n",
    "        'Chinese (Mandarin)_Bright_Light',\n",
    "        'Chinese (Mandarin)_Sweet_Girl',\n",
    "        'Chinese (Mandarin)_Young_Man',\n",
    "        'Chinese (Mandarin)_Deep_Dad',\n",
    "        'Chinese (Mandarin)_Calm_Mom',\n",
    "        'Chinese (Mandarin)_Narrator_Professional',\n",
    "        'Chinese (Mandarin)_Narrator_Soft',\n",
    "        'Chinese (Mandarin)_Child_Boy',\n",
    "        'Chinese (Mandarin)_Child_Girl',\n",
    "        'Chinese (Mandarin)_Elder_Grandpa',\n",
    "        'Chinese (Mandarin)_Elder_Grandma',\n",
    "        'Chinese (Mandarin)_News_Anchor',\n",
    "        'Chinese (Mandarin)_Cartoon_Bear',\n",
    "        'Chinese (Mandarin)_Cartoon_Duck',\n",
    "        'Chinese (Mandarin)_Cartoon_Fox',\n",
    "        'Chinese (Mandarin)_Cartoon_Robot'\n",
    "    ],\n",
    "    'English': [\n",
    "        'English_Graceful_Lady',\n",
    "        'English_Persuasive_Man'\n",
    "    ],\n",
    "    'Japanese': [\n",
    "        'Japanese_Whisper_Belle'\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Input widgets\n",
    "input_text_widget = widgets.Textarea(\n",
    "    value='', description='文字內容:', style=label_style, layout=wide_textarea_layout\n",
    ")\n",
    "preview_text_widget = widgets.Textarea(\n",
    "    value='', description='試聽文字:', style=label_style, layout=wide_preview_textarea_layout\n",
    ")\n",
    "preview_button = widgets.Button(description='語音試聽', button_style='info', layout=widgets.Layout(width='350px', height='60px'))\n",
    "audio_output = widgets.Output(layout=wide_layout)\n",
    "save_button = widgets.Button(description='確定儲存', button_style='success', layout=widgets.Layout(width='350px', height='60px'))\n",
    "output = widgets.Output(layout=wide_layout)\n",
    "\n",
    "tts_server_widget = widgets.Dropdown(\n",
    "    options=[('Azure', 'azure'), ('MINIMAX', 'minimax')],\n",
    "    value='azure', description='TTS伺服器:', style=label_style, layout=wide_layout\n",
    ")\n",
    "\n",
    "# Azure widgets\n",
    "azure_voice_widget = widgets.Dropdown(\n",
    "    options=azure_voice_options, value=azure_voice_options[0],\n",
    "    description='Azure語音:', style=label_style, layout=wide_layout\n",
    ")\n",
    "azure_speed_widget = widgets.FloatSlider(value=1.0, min=0.5, max=2.0, step=0.01, description='語速:', style=label_style, layout=wide_layout)\n",
    "azure_pitch_widget = widgets.IntSlider(value=0, min=-12, max=12, step=1, description='語調:', style=label_style, layout=wide_layout)\n",
    "\n",
    "# MINIMAX widgets\n",
    "minimax_model_widget = widgets.Dropdown(\n",
    "    options=['speech-02-hd', 'speech-2.5-hd-preview'], value='speech-02-hd', description='MINIMAX模型:', style=label_style, layout=wide_layout)\n",
    "minimax_accent_widget = widgets.Dropdown(\n",
    "    options=minimax_accent_options, value='Chinese (Mandarin)', description='MINIMAX腔調:', style=label_style, layout=wide_layout\n",
    ")\n",
    "minimax_voice_widget = widgets.Dropdown(\n",
    "    options=minimax_voice_dict['Chinese (Mandarin)'], value=minimax_voice_dict['Chinese (Mandarin)'][0],\n",
    "    description='MINIMAX語音:', style=label_style, layout=wide_layout\n",
    ")\n",
    "minimax_emotion_widget = widgets.Dropdown(\n",
    "    options=['calm', 'happy', 'sad', 'angry', 'fearful', 'disgusted', 'surprised'],\n",
    "    value='calm', description='MINIMAX情感:', style=label_style, layout=wide_layout)\n",
    "minimax_vol_widget = widgets.FloatSlider(value=1.0, min=0.1, max=10.0, step=0.1, description='MINIMAX音量:', style=label_style, layout=wide_layout)\n",
    "minimax_speed_widget = widgets.FloatSlider(value=1.0, min=0.5, max=2.0, step=0.01, description='語速:', style=label_style, layout=wide_layout)\n",
    "minimax_pitch_widget = widgets.IntSlider(value=0, min=-12, max=12, step=1, description='語調:', style=label_style, layout=wide_layout)\n",
    "minimax_audio_format_widget = widgets.Dropdown(\n",
    "    options=['mp3', 'wav'], value='mp3', description='MINIMAX音檔格式:', style=label_style, layout=wide_layout)\n",
    "minimax_sample_rate_widget = widgets.Dropdown(\n",
    "    options=[32000, 44100], value=32000, description='MINIMAX取樣率:', style=label_style, layout=wide_layout)\n",
    "minimax_bitrate_widget = widgets.Dropdown(\n",
    "    options=[128000, 256000], value=128000, description='MINIMAX比特率:', style=label_style, layout=wide_layout)\n",
    "minimax_channel_widget = widgets.Dropdown(\n",
    "    options=[1, 2], value=1, description='MINIMAX聲道:', style=label_style, layout=wide_layout)\n",
    "\n",
    "# Accent change updates voice list\n",
    "def update_minimax_voices(*args):\n",
    "    accent = minimax_accent_widget.value\n",
    "    minimax_voice_widget.options = minimax_voice_dict[accent]\n",
    "    minimax_voice_widget.value = minimax_voice_dict[accent][0]\n",
    "minimax_accent_widget.observe(update_minimax_voices, names='value')\n",
    "\n",
    "# --- Project info widgets ---\n",
    "project_title_widget = widgets.Text(value='test', description='專案名稱:', style=label_style, layout=wide_layout)\n",
    "project_author_widget = widgets.Text(value='', description='作者:', style=label_style, layout=wide_layout)\n",
    "bgm_volume_widget = widgets.FloatSlider(value=0.3, min=0, max=1, step=0.01, description='BGM音量:', style=label_style, layout=wide_layout)\n",
    "attribution_widget = widgets.Text(value='', description='版權說明:', style=label_style, layout=wide_layout)\n",
    "subtitle_font_widget = widgets.Text(value='NotoSansCJKtc-Regular.otf', description='字幕字型:', style=label_style, layout=wide_layout)\n",
    "subtitle_fontsize_widget = widgets.IntSlider(value=30, min=10, max=80, step=1, description='字幕字體大小:', style=label_style, layout=wide_layout)\n",
    "video_resolution_widget = widgets.Text(value='1920,1080', description='影片解析度:', style=label_style, layout=wide_layout)\n",
    "\n",
    "# --- Dynamically list images and audio from ammunition directory ---\n",
    "def get_ammunition_files(extension_list):\n",
    "    files = []\n",
    "    if os.path.isdir(\"ammunition\"):\n",
    "        for fname in os.listdir(\"ammunition\"):\n",
    "            if any(fname.lower().endswith(ext) for ext in extension_list):\n",
    "                files.append(fname)\n",
    "    return files if files else [\"(無符合檔案)\"]\n",
    "\n",
    "background_image_options = get_ammunition_files(['.jpg', '.jpeg', '.png', '.bmp', '.webp'])\n",
    "bgm_audio_options = get_ammunition_files(['.mp3', '.wav', '.aac', '.m4a', '.flac', '.ogg'])\n",
    "\n",
    "background_file_widget = widgets.Dropdown(\n",
    "    options=background_image_options,\n",
    "    value=background_image_options[0],\n",
    "    description='背景檔:', style=label_style, layout=wide_layout\n",
    ")\n",
    "bgm_file_widget = widgets.Dropdown(\n",
    "    options=bgm_audio_options,\n",
    "    value=bgm_audio_options[0],\n",
    "    description='BGM檔:', style=label_style, layout=wide_layout\n",
    ")\n",
    "\n",
    "thumbnail_file_widget = widgets.Text(value='thumbnail.jpg', description='縮圖檔:', style=label_style, layout=wide_layout)\n",
    "text_file_widget = widgets.Text(value='text.txt', description='文字檔:', style=label_style, layout=wide_layout)\n",
    "\n",
    "project_info_box = widgets.VBox([\n",
    "    project_title_widget, project_author_widget, bgm_volume_widget,\n",
    "    attribution_widget, subtitle_font_widget, subtitle_fontsize_widget,\n",
    "    video_resolution_widget, background_file_widget, bgm_file_widget,\n",
    "    thumbnail_file_widget, text_file_widget\n",
    "])\n",
    "\n",
    "# --- Dynamic param box ---\n",
    "param_box = widgets.VBox()\n",
    "def update_param_box(*args):\n",
    "    if tts_server_widget.value == 'azure':\n",
    "        param_box.children = [azure_voice_widget, azure_speed_widget, azure_pitch_widget]\n",
    "    else:\n",
    "        param_box.children = [\n",
    "            minimax_model_widget, minimax_accent_widget, minimax_voice_widget, minimax_emotion_widget,\n",
    "            minimax_vol_widget, minimax_speed_widget, minimax_pitch_widget,\n",
    "            minimax_audio_format_widget, minimax_sample_rate_widget, minimax_bitrate_widget, minimax_channel_widget\n",
    "        ]\n",
    "update_param_box()\n",
    "tts_server_widget.observe(update_param_box, names='value')\n",
    "\n",
    "# ---- TTS Functions ----\n",
    "def azure_tts_api(text, voice, speed, pitch):\n",
    "    AZURE_SPEECH_KEY = os.environ.get(\"AZURE_SPEECH_KEY\")\n",
    "    AZURE_SPEECH_REGION = os.environ.get(\"AZURE_SPEECH_REGION\")\n",
    "    if not AZURE_SPEECH_KEY or not AZURE_SPEECH_REGION:\n",
    "        print(\"Azure API key 或 region 未設定。\")\n",
    "        return None\n",
    "    try:\n",
    "        import azure.cognitiveservices.speech as speechsdk\n",
    "        speech_config = speechsdk.SpeechConfig(subscription=AZURE_SPEECH_KEY, region=AZURE_SPEECH_REGION)\n",
    "        speech_config.speech_synthesis_voice_name = voice\n",
    "        synthesizer = speechsdk.SpeechSynthesizer(speech_config=speech_config)\n",
    "        result = synthesizer.speak_text_async(text).get()\n",
    "        if result.reason == speechsdk.ResultReason.Canceled:\n",
    "            cancellation_details = speechsdk.CancellationDetails(result)\n",
    "            print(f\"Azure TTS失敗: {cancellation_details.reason}\\n{cancellation_details.error_details}\")\n",
    "            return None\n",
    "        if result.reason == speechsdk.ResultReason.SynthesizingAudioCompleted:\n",
    "            tf = tempfile.NamedTemporaryFile(delete=False, suffix='.wav')\n",
    "            tf.write(result.audio_data)\n",
    "            tf.close()\n",
    "            return tf.name\n",
    "        else:\n",
    "            print(f\"Azure TTS失敗: {getattr(result, 'error_details', str(result.reason))}\")\n",
    "    except Exception as e:\n",
    "        print(\"Azure TTS執行錯誤:\", str(e))\n",
    "    return None\n",
    "\n",
    "def minimax_tts_api(text, model, voice, emotion, vol, speed, pitch, audio_format, sample_rate, bitrate, channel):\n",
    "    MINIMAX_SPEECH_KEY = os.getenv('MINIMAX_SPEECH_KEY')\n",
    "    url = f\"https://api.minimax.io/v1/t2a_v2?GroupId=1982992498867311582\"\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {MINIMAX_SPEECH_KEY}\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    payload = {\n",
    "        \"model\": model,\n",
    "        \"text\": text,\n",
    "        \"voice_setting\": {\n",
    "            \"voice_id\": voice,\n",
    "            \"speed\": speed,\n",
    "            \"vol\": vol,\n",
    "            \"pitch\": pitch,\n",
    "            \"emotion\": emotion\n",
    "        },\n",
    "        \"audio_setting\": {\n",
    "            \"sample_rate\": sample_rate,\n",
    "            \"bitrate\": bitrate,\n",
    "            \"format\": audio_format,\n",
    "            \"channel\": channel\n",
    "        },\n",
    "        \"output_format\": \"url\",\n",
    "        \"language_boost\": \"auto\",\n",
    "        \"subtitle_enable\": False\n",
    "    }\n",
    "    try:\n",
    "        r = requests.post(url, headers=headers, json=payload)\n",
    "        if r.status_code == 200:\n",
    "            data = r.json()\n",
    "            base_resp = data.get(\"base_resp\", {})\n",
    "            if base_resp.get(\"status_code\") == 0:\n",
    "                audio_url = data.get(\"data\", {}).get(\"audio\")\n",
    "                if audio_url:\n",
    "                    r2 = requests.get(audio_url)\n",
    "                    if r2.status_code == 200:\n",
    "                        with tempfile.NamedTemporaryFile(delete=False, suffix='.'+audio_format) as tf:\n",
    "                            tf.write(r2.content)\n",
    "                            temp_audio_path = tf.name\n",
    "                        return temp_audio_path\n",
    "                    else:\n",
    "                        print(\"MINIMAX音檔下載失敗：\", r2.status_code)\n",
    "                else:\n",
    "                    print(\"MINIMAX未取得音檔URL，請檢查API回應！\")\n",
    "            else:\n",
    "                print(\"MINIMAX API錯誤：\", base_resp.get(\"status_msg\"))\n",
    "        else:\n",
    "            print(\"MINIMAX TTS API失敗，狀態碼：\", r.status_code)\n",
    "            print(\"回應：\", r.text[:300])\n",
    "            print(\"Payload used:\\n\", payload)\n",
    "    except Exception as e:\n",
    "        print(\"MINIMAX TTS試聽錯誤：\", e)\n",
    "    return None\n",
    "\n",
    "def on_preview_clicked(b):\n",
    "    with audio_output:\n",
    "        audio_output.clear_output()\n",
    "        preview_text = preview_text_widget.value.strip()\n",
    "        if not preview_text:\n",
    "            print(\"請輸入欲試聽的語音文字！\")\n",
    "            return\n",
    "        if tts_server_widget.value == 'azure':\n",
    "            temp_audio_path = azure_tts_api(\n",
    "                preview_text, azure_voice_widget.value, azure_speed_widget.value, azure_pitch_widget.value)\n",
    "        else:\n",
    "            temp_audio_path = minimax_tts_api(\n",
    "                preview_text, minimax_model_widget.value, minimax_voice_widget.value,\n",
    "                minimax_emotion_widget.value, minimax_vol_widget.value,\n",
    "                minimax_speed_widget.value, minimax_pitch_widget.value,\n",
    "                minimax_audio_format_widget.value, minimax_sample_rate_widget.value,\n",
    "                minimax_bitrate_widget.value, minimax_channel_widget.value)\n",
    "        if temp_audio_path:\n",
    "            display(Audio(temp_audio_path, autoplay=True))\n",
    "            print(f\"{tts_server_widget.value}語音試聽成功！\")\n",
    "\n",
    "preview_button.on_click(on_preview_clicked)\n",
    "\n",
    "def on_save_clicked(b):\n",
    "    # Enforce project_title is not empty\n",
    "    project_title_value = project_title_widget.value.strip() if project_title_widget.value.strip() else \"test\"\n",
    "    project_title_widget.value = project_title_value  # update widget if needed\n",
    "\n",
    "    config = {\n",
    "        'input_text': input_text_widget.value,\n",
    "        'preview_text': preview_text_widget.value,\n",
    "        'tts_server': tts_server_widget.value,\n",
    "        'azure_voice': azure_voice_widget.value,\n",
    "        'azure_speed': azure_speed_widget.value,\n",
    "        'azure_pitch': azure_pitch_widget.value,\n",
    "        'minimax_model': minimax_model_widget.value,\n",
    "        'minimax_accent': minimax_accent_widget.value,\n",
    "        'minimax_voice': minimax_voice_widget.value,\n",
    "        'minimax_emotion': minimax_emotion_widget.value,\n",
    "        'minimax_vol': minimax_vol_widget.value,\n",
    "        'minimax_speed': minimax_speed_widget.value,\n",
    "        'minimax_pitch': minimax_pitch_widget.value,\n",
    "        'minimax_audio_format': minimax_audio_format_widget.value,\n",
    "        'minimax_sample_rate': minimax_sample_rate_widget.value,\n",
    "        'minimax_bitrate': minimax_bitrate_widget.value,\n",
    "        'minimax_channel': minimax_channel_widget.value,\n",
    "        'project_title': project_title_value,\n",
    "        'project_author': project_author_widget.value,\n",
    "        'bgm_volume': bgm_volume_widget.value,\n",
    "        'attribution': attribution_widget.value,\n",
    "        'subtitle_font': subtitle_font_widget.value,\n",
    "        'subtitle_fontsize': subtitle_fontsize_widget.value,\n",
    "        'video_resolution': video_resolution_widget.value,\n",
    "        'background': background_file_widget.value,\n",
    "        'bgm': bgm_file_widget.value,\n",
    "        'thumbnail': thumbnail_file_widget.value,\n",
    "        'text': text_file_widget.value,\n",
    "    }\n",
    "    with output:\n",
    "        output.clear_output()\n",
    "        # 儲存 config.yaml\n",
    "        yaml.safe_dump(config, open('config.yaml', 'w', encoding='utf-8'), allow_unicode=True)\n",
    "        # 同步寫入 text.txt\n",
    "        try:\n",
    "            with open(text_file_widget.value, 'w', encoding='utf-8') as f:\n",
    "                f.write(input_text_widget.value)\n",
    "            print('設定已儲存到 config.yaml，且文字內容已同步寫入 text.txt！')\n",
    "        except Exception as e:\n",
    "            print(f\"[ERROR] 寫入 text.txt 失敗：{e}\")\n",
    "        print(config)\n",
    "        if project_title_value == \"test\":\n",
    "            print(\"⚠️ 專案名稱為 test，請在專案開始前確認填寫正確名稱。\")\n",
    "\n",
    "save_button.on_click(on_save_clicked)\n",
    "\n",
    "# ---- Display all widgets ----\n",
    "display(\n",
    "    input_text_widget,\n",
    "    preview_text_widget,\n",
    "    preview_button,\n",
    "    audio_output,\n",
    "    tts_server_widget,\n",
    "    param_box,\n",
    "    project_info_box,\n",
    "    save_button,\n",
    "    output\n",
    ")\n",
    "print(\"=\"*40)\n",
    "print(f\"專案名稱: {project_title}\")\n",
    "print(f\"Current subdir: {subdir}\")\n",
    "print(f\"目前工作目錄：{os.getcwd()}\")\n",
    "print(\"=\"*40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be01d426-40f8-413c-a1cc-0aab7157e92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cell 4-8\n",
    "\n",
    "import os\n",
    "import yaml\n",
    "import shutil\n",
    "import datetime\n",
    "import re\n",
    "from snownlp import SnowNLP\n",
    "import subprocess\n",
    "from tqdm.notebook import tqdm\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "print(\"=== STEP 0: 專案資料 ===\")\n",
    "main_dir = os.getcwd()\n",
    "ammunition_dir = os.path.join(main_dir, \"ammunition\")\n",
    "print(\"Current subdir:\", main_dir)\n",
    "print(\"目前工作目錄：\", os.getcwd())\n",
    "print(\"資源目錄(ammunition):\", ammunition_dir)\n",
    "\n",
    "print(\"\\n=== STEP 1: 讀取 config 及同步更新 text.txt ===\")\n",
    "# ---- Load config ----\n",
    "try:\n",
    "    with open('config.yaml', encoding='utf-8') as f:\n",
    "        config = yaml.safe_load(f)\n",
    "except Exception as e:\n",
    "    print(f\"[ERROR] Failed to load config.yaml: {e}\")\n",
    "    raise\n",
    "\n",
    "project_title = config.get('project_title', config.get('title', 'My YouTube Video'))\n",
    "project_author = config.get('project_author', 'Anonymous')\n",
    "bgm_volume = config.get('bgm_volume', 0.3)\n",
    "attribution = config.get('attribution', 'Assets used under free license. See description.')\n",
    "\n",
    "background_file = os.path.join(ammunition_dir, config.get('background', 'background.jpg'))\n",
    "bgm_file = os.path.join(ammunition_dir, config.get('bgm', 'bgm.mp3'))\n",
    "subtitle_font = os.path.join(ammunition_dir, config.get('subtitle_font', 'NotoSansCJKtc-Regular.otf'))\n",
    "thumbnail_file = os.path.join(ammunition_dir, config.get('thumbnail', 'thumbnail.jpg'))\n",
    "text_file = os.path.join(ammunition_dir, config.get('text', 'text.txt'))\n",
    "\n",
    "required_files = [background_file, bgm_file, text_file, subtitle_font, thumbnail_file]\n",
    "for fname in required_files:\n",
    "    if not os.path.exists(fname):\n",
    "        print(f\"[WARNING] Missing file: {fname}\")\n",
    "\n",
    "print(\"=\"*30)\n",
    "\n",
    "# --- 關鍵步驟：先用 config['input_text'] 覆蓋 text.txt ---\n",
    "input_text = config.get('input_text', '')\n",
    "with open(text_file, 'w', encoding='utf-8') as f:\n",
    "    f.write(input_text)\n",
    "\n",
    "# --- 讀取 text.txt 的內容為句子 ---\n",
    "try:\n",
    "    with open(text_file, 'r', encoding='utf-8') as f:\n",
    "        sentences = [line.strip() for line in f if line.strip()]\n",
    "except Exception as e:\n",
    "    print(f\"[ERROR] Failed to read text file: {e}\")\n",
    "    sentences = []\n",
    "\n",
    "print(f\"已載入 {len(sentences)} 句子，來源: {text_file}\")\n",
    "print(f\"TTS server: {config.get('tts_server', 'azure')}\")\n",
    "print(f\"字幕字型: {subtitle_font}, 字體大小: {config.get('subtitle_fontsize', 30)}\")\n",
    "print(f\"影片解析度: {config.get('video_resolution', [1920, 1080])}\")\n",
    "print(f\"背景檔: {background_file}\")\n",
    "print(f\"BGM檔: {bgm_file}\")\n",
    "print(f\"縮圖檔: {thumbnail_file}\")\n",
    "print(\"=\"*30)\n",
    "\n",
    "print(\"\\n=== STEP 2: 建立 subdir 並複製資源 ===\")\n",
    "today = datetime.datetime.now().strftime(\"%Y%m%d\")\n",
    "safe_title = re.sub(r'[\\\\/:*?\"<>|\\n\\r\\t]', '', project_title)[:20]\n",
    "subdir = os.path.join(main_dir, f\"{today}_{safe_title}\")\n",
    "\n",
    "try:\n",
    "    if not os.path.exists(subdir):\n",
    "        os.makedirs(subdir)\n",
    "except Exception as e:\n",
    "    print(f\"[ERROR] Failed to create subdir: {e}\")\n",
    "    raise\n",
    "\n",
    "for fname in required_files:\n",
    "    target = os.path.join(subdir, os.path.basename(fname))\n",
    "    try:\n",
    "        if not os.path.exists(target) or not os.path.samefile(fname, target):\n",
    "            shutil.copy2(fname, target)\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Failed to copy {fname} to {target}: {e}\")\n",
    "\n",
    "print(f\"All required files are available in subdir.\")\n",
    "\n",
    "print(\"\\n=== STEP 3: 句子分割與清理 ===\")\n",
    "try:\n",
    "    with open(os.path.join(subdir, os.path.basename(text_file)), encoding=\"utf-8\") as f:\n",
    "        text = f.read().strip()\n",
    "except Exception as e:\n",
    "    print(f\"[ERROR] Failed to read {os.path.join(subdir, os.path.basename(text_file))}: {e}\")\n",
    "    text = \"\"\n",
    "\n",
    "def is_pronounceable(s):\n",
    "    return bool(re.search(r'[\\u4e00-\\u9fffA-Za-z0-9]', s))\n",
    "\n",
    "def clean_markdown(s):\n",
    "    s = re.sub(r\"^[#\\-\\*\\s>]+\", \"\", s)\n",
    "    s = re.sub(r\"(\\*|`|_|>|#|\\[|\\]|\\(|\\)|\\-|~|=|>)\", \"\", s)\n",
    "    s = re.sub(r\"[「」]\", \"\", s)\n",
    "    s = re.sub(r\"\\s+\", \" \", s)\n",
    "    return s.strip()\n",
    "\n",
    "try:\n",
    "    sentences = [s.strip() for s in SnowNLP(text).sentences if s.strip()]\n",
    "except Exception as e:\n",
    "    print(f\"[ERROR] SnowNLP sentence segmentation failed: {e}\")\n",
    "    sentences = [text] if text else []\n",
    "\n",
    "sentences = [clean_markdown(s) for s in sentences if is_pronounceable(s)]\n",
    "sentences = [s for s in sentences if is_pronounceable(s)]\n",
    "\n",
    "print(f\"Total sentences after filtering: {len(sentences)}\")\n",
    "for idx, s in enumerate(sentences):\n",
    "    print(f\"{idx}: '{s}'\")\n",
    "\n",
    "print(\"\\n=== STEP 4: TTS 語音合成 ===\")\n",
    "load_dotenv()\n",
    "tts_server = config.get('tts_server', 'azure')\n",
    "audio_files, durations, error_log = [], [], []\n",
    "failed_sentences = []\n",
    "max_retries = 3\n",
    "\n",
    "if tts_server == 'azure':\n",
    "    import azure.cognitiveservices.speech as speechsdk\n",
    "    AZURE_SPEECH_KEY = os.environ.get(\"AZURE_SPEECH_KEY\")\n",
    "    AZURE_SPEECH_REGION = os.environ.get(\"AZURE_SPEECH_REGION\")\n",
    "    VOICE = config.get('azure_voice', 'zh-TW-YunJheNeural')\n",
    "    print(f\"[CHECK] Azure voice_id (voice_name) used for synthesis: {VOICE}\")\n",
    "    for i, sentence in enumerate(sentences):\n",
    "        speech_config = speechsdk.SpeechConfig(subscription=AZURE_SPEECH_KEY, region=AZURE_SPEECH_REGION)\n",
    "        speech_config.speech_synthesis_voice_name = VOICE\n",
    "        speech_config.set_speech_synthesis_output_format(\n",
    "            speechsdk.SpeechSynthesisOutputFormat.Audio16Khz32KBitRateMonoMp3\n",
    "        )\n",
    "        mp3_fname = os.path.join(subdir, f\"voice_{i}.mp3\")\n",
    "        audio_config = speechsdk.audio.AudioOutputConfig(filename=mp3_fname)\n",
    "        synthesizer = speechsdk.SpeechSynthesizer(speech_config=speech_config, audio_config=audio_config)\n",
    "        result = synthesizer.speak_text_async(sentence).get()\n",
    "        if result.reason == speechsdk.ResultReason.SynthesizingAudioCompleted:\n",
    "            print(f\"[OK] 合成完成: {mp3_fname}\")\n",
    "            audio_files.append(mp3_fname)\n",
    "        elif result.reason == speechsdk.ResultReason.Canceled:\n",
    "            cancellation_details = speechsdk.CancellationDetails(result)\n",
    "            print(f\"[ERROR] 合成失敗: {sentence}\")\n",
    "            print(f\"Reason: {cancellation_details.reason}\")\n",
    "            print(f\"Details: {cancellation_details.error_details}\")\n",
    "            failed_sentences.append((i, sentence))\n",
    "        else:\n",
    "            print(f\"[ERROR] TTS失敗(未知): {sentence}, Reason: {result.reason}\")\n",
    "            failed_sentences.append((i, sentence))\n",
    "elif tts_server == 'minimax':\n",
    "    import requests\n",
    "    MINIMAX_SPEECH_KEY = os.environ.get(\"MINIMAX_SPEECH_KEY\")\n",
    "    MINIMAX_URL = \"https://api.minimax.io/v1/t2a_v2?GroupId=1982992498867311582\"\n",
    "    MODEL = config.get(\"minimax_model\", \"speech-02-hd\")\n",
    "    VOICE = config.get(\"minimax_voice\", \"Chinese (Mandarin)_Warm_Bestie\")\n",
    "    EMOTION = config.get(\"minimax_emotion\", \"calm\")\n",
    "    VOL = config.get(\"minimax_vol\", 1.0)\n",
    "    SPEED = config.get(\"minimax_speed\", 1.0)\n",
    "    PITCH = config.get(\"minimax_pitch\", 0)\n",
    "    AUDIO_FORMAT = config.get(\"minimax_audio_format\", \"mp3\")\n",
    "    SAMPLE_RATE = config.get(\"minimax_sample_rate\", 32000)\n",
    "    BITRATE = config.get(\"minimax_bitrate\", 128000)\n",
    "    CHANNEL = config.get(\"minimax_channel\", 1)\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {MINIMAX_SPEECH_KEY}\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    print(f\"[CHECK] MINIMAX voice_id (voice_name) used for synthesis: {VOICE}\")\n",
    "    for i, sentence in enumerate(sentences):\n",
    "        payload = {\n",
    "            \"model\": MODEL,\n",
    "            \"text\": sentence,\n",
    "            \"voice_setting\": {\n",
    "                \"voice_id\": VOICE,\n",
    "                \"speed\": SPEED,\n",
    "                \"vol\": VOL,\n",
    "                \"pitch\": PITCH,\n",
    "                \"emotion\": EMOTION\n",
    "            },\n",
    "            \"audio_setting\": {\n",
    "                \"sample_rate\": SAMPLE_RATE,\n",
    "                \"bitrate\": BITRATE,\n",
    "                \"format\": AUDIO_FORMAT,\n",
    "                \"channel\": CHANNEL\n",
    "            },\n",
    "            \"output_format\": \"url\",\n",
    "            \"language_boost\": \"auto\",\n",
    "            \"subtitle_enable\": False\n",
    "        }\n",
    "        r = requests.post(MINIMAX_URL, headers=headers, json=payload)\n",
    "        if r.status_code == 200:\n",
    "            data = r.json()\n",
    "            base_resp = data.get(\"base_resp\", {})\n",
    "            if base_resp.get(\"status_code\") == 0:\n",
    "                audio_url = data.get(\"data\", {}).get(\"audio\")\n",
    "                if audio_url:\n",
    "                    r2 = requests.get(audio_url)\n",
    "                    if r2.status_code == 200:\n",
    "                        fname = os.path.join(subdir, f\"voice_{i}.{AUDIO_FORMAT}\")\n",
    "                        with open(fname, \"wb\") as f:\n",
    "                            f.write(r2.content)\n",
    "                        print(f\"[OK] MINIMAX合成完成: {fname}\")\n",
    "                        audio_files.append(fname)\n",
    "                    else:\n",
    "                        print(f\"[ERROR] MINIMAX音檔下載失敗: {r2.status_code}\")\n",
    "                        failed_sentences.append((i, sentence))\n",
    "                else:\n",
    "                    print(f\"[ERROR] MINIMAX未取得音檔URL: {data}\")\n",
    "                    failed_sentences.append((i, sentence))\n",
    "            else:\n",
    "                print(f\"[ERROR] MINIMAX API錯誤: {base_resp.get('status_msg', '')}\")\n",
    "                failed_sentences.append((i, sentence))\n",
    "        else:\n",
    "            print(f\"[ERROR] MINIMAX TTS API HTTP錯誤: {r.status_code}\")\n",
    "            failed_sentences.append((i, sentence))\n",
    "else:\n",
    "    print(\"[ERROR] 未支援的 TTS server 設定：\", tts_server)\n",
    "\n",
    "print(\"TTS synthesis complete. Valid files:\", len(audio_files))\n",
    "if failed_sentences:\n",
    "    print(\"Failed sentences:\")\n",
    "    for idx, s in failed_sentences:\n",
    "        print(f\"Sentence {idx}: '{s}'\")\n",
    "\n",
    "# === STEP 5: 驗證音檔並產生分鏡表用資料 ===\n",
    "valid_sentences = []\n",
    "valid_audio_files = []\n",
    "valid_durations = []\n",
    "\n",
    "for i, sentence in enumerate(sentences):\n",
    "    mp3_fname = os.path.join(subdir, f\"voice_{i}.mp3\")\n",
    "    if os.path.exists(mp3_fname) and os.path.getsize(mp3_fname) > 0:\n",
    "        r = subprocess.run([\n",
    "            \"ffprobe\", \"-v\", \"error\", \"-show_entries\",\n",
    "            \"format=duration\", \"-of\", \"default=noprint_wrappers=1:nokey=1\", mp3_fname\n",
    "        ], capture_output=True)\n",
    "        try:\n",
    "            duration_val = float(r.stdout.decode().strip())\n",
    "            if duration_val > 0.01 and duration_val < 30:\n",
    "                valid_durations.append(duration_val)\n",
    "                valid_audio_files.append(mp3_fname)\n",
    "                valid_sentences.append(sentence)\n",
    "                print(f\"OK: {i}: '{sentence}' ({duration_val:.2f}s)\")\n",
    "            else:\n",
    "                print(f\"Skipped {i}: '{sentence}' - duration {duration_val:.2f}s\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading duration for {mp3_fname}: {e}\")\n",
    "    else:\n",
    "        print(f\"Missing or empty audio: {i}: '{sentence}'\")\n",
    "\n",
    "print(f\"\\nKept {len(valid_audio_files)} valid audio files and sentences\")\n",
    "if valid_sentences and valid_sentences[-1] == sentences[-1]:\n",
    "    print(\"✅ Last sentence included:\", valid_sentences[-1])\n",
    "else:\n",
    "    print(\"❌ Last sentence missing! Check synthesis and validation steps.\")\n",
    "\n",
    "# 關鍵：分鏡表資料存成 global 變數，供 cell8.1 widget 讀取\n",
    "globals()[\"valid_sentences\"] = valid_sentences\n",
    "globals()[\"valid_audio_files\"] = valid_audio_files\n",
    "\n",
    "# 合併所有有效語音檔成 voice.mp3（供後續用）\n",
    "files_txt = os.path.join(subdir, \"files.txt\")\n",
    "with open(files_txt, \"w\", encoding=\"utf-8\") as f:\n",
    "    for af in valid_audio_files:\n",
    "        f.write(f\"file '{af}'\\n\")\n",
    "\n",
    "voice_mp3 = os.path.join(subdir, \"voice.mp3\")\n",
    "concat_result = subprocess.run(\n",
    "    [\"ffmpeg\", \"-y\", \"-f\", \"concat\", \"-safe\", \"0\", \"-i\", files_txt, \"-c\", \"copy\", voice_mp3],\n",
    "    capture_output=True\n",
    ")\n",
    "if concat_result.returncode != 0:\n",
    "    print(\"[FFmpeg Error] Failed to concatenate audio files.\")\n",
    "    print(concat_result.stderr.decode())\n",
    "else:\n",
    "    print(\"Concatenated voice.mp3 created successfully.\")\n",
    "\n",
    "print(\"=\"*40)\n",
    "print(f\"專案名稱: {project_title}\")\n",
    "print(f\"Current subdir: {subdir}\")\n",
    "print(f\"目前工作目錄：{os.getcwd()}\")\n",
    "print(\"=\"*40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c68592-de5d-40a2-98b9-9f62d7555127",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 8.5\n",
    "import os\n",
    "import openai\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "from IPython.display import display, Image as IPyImage, FileLink\n",
    "import requests\n",
    "import ipywidgets as widgets\n",
    "import yaml\n",
    "from dotenv import load_dotenv\n",
    "import subprocess\n",
    "import re\n",
    "import functools\n",
    "\n",
    "# --- 基本環境讀取 ---\n",
    "load_dotenv()\n",
    "openai.api_key = os.getenv(\"OPENAI_API\")\n",
    "\n",
    "print(\"專案名稱:\", config.get(\"project_title\", config.get(\"title\", \"未設定\")))\n",
    "print(\"Current subdir:\", subdir)\n",
    "print(\"目前工作目錄：\", os.getcwd())\n",
    "\n",
    "ammunition_dir = os.path.join(main_dir, \"ammunition\")\n",
    "text_path = os.path.join(ammunition_dir, \"text.txt\")\n",
    "with open(text_path, encoding=\"utf-8\") as f:\n",
    "    script_text = f.read().strip()\n",
    "\n",
    "# --- 1️⃣ 語意分割字幕為場景（GPT-3.5，最多4個）---\n",
    "def semantic_scene_split(subtitles, max_scene=4):\n",
    "    prompt = (\n",
    "        \"請將以下字幕依語意分割為不超過4個場景，每個場景列出起迄句子編號（如：1-5，6-8），只需輸出每個場景的起迄範圍，不需解釋：\\n\"\n",
    "        + \"\\n\".join([f\"{i+1}. {s}\" for i, s in enumerate(subtitles)])\n",
    "    )\n",
    "    resp = openai.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    content = resp.choices[0].message.content\n",
    "    ranges = []\n",
    "    for line in content.splitlines():\n",
    "        m = re.match(r\"(\\d+)\\s*-\\s*(\\d+)\", line)\n",
    "        if m:\n",
    "            start = int(m.group(1)) - 1\n",
    "            end = int(m.group(2))\n",
    "            ranges.append((start, end))\n",
    "    if not ranges:\n",
    "        ranges = [(0, len(subtitles))]\n",
    "    return ranges[:max_scene]\n",
    "\n",
    "scene_ranges = semantic_scene_split(valid_sentences)\n",
    "scene_images = [None] * len(scene_ranges)\n",
    "scene_img_names = [None] * len(scene_ranges)\n",
    "\n",
    "# --- 2️⃣ 分場景UI + AI圖生成/手動選檔案 ---\n",
    "def sanitize_title(title):\n",
    "    return re.sub(r\"[^\\u4e00-\\u9fa5A-Za-z0-9]\", \"\", title)[:10] or \"scene\"\n",
    "\n",
    "def dalle3_generate(prompt, idx, seg_sentences, size=\"1792x1024\"):\n",
    "    scene_title = sanitize_title(seg_sentences[0]) if seg_sentences else f\"scene{idx+1}\"\n",
    "    fname = os.path.join(subdir, f\"ai_scene_{idx+1}_{scene_title}.jpg\")\n",
    "    print(f\"呼叫DALL·E生成場景{idx+1}: {scene_title}\")\n",
    "    response = openai.images.generate(\n",
    "        model=\"dall-e-3\",\n",
    "        prompt=prompt,\n",
    "        size=size,\n",
    "        n=1,\n",
    "        quality=\"standard\"\n",
    "    )\n",
    "    url = response.data[0].url\n",
    "    imgdata = requests.get(url).content\n",
    "    img = Image.open(BytesIO(imgdata))\n",
    "    img_resized = img.resize((1920, 1080), resample=Image.LANCZOS)\n",
    "    img_resized.save(fname, format=\"JPEG\")\n",
    "    print(f\"AI場景圖片已儲存：{fname}\")\n",
    "    return fname\n",
    "\n",
    "try:\n",
    "    all_files = os.listdir(ammunition_dir)\n",
    "except Exception as e:\n",
    "    print(f\"[ERROR] Failed to list ammunition_dir: {e}\")\n",
    "    all_files = []\n",
    "\n",
    "image_files = [f for f in all_files if f.lower().endswith(('.jpg', '.png'))]\n",
    "\n",
    "# --- 3️⃣ 分鏡表（先建立bg_selectors，方便後續直接value設定） ---\n",
    "video_files = [f for f in all_files if f.lower().endswith(('.mp4', '.mov', '.avi'))]\n",
    "music_files = [f for f in all_files if f.lower().endswith(('.mp3', '.wav'))]\n",
    "\n",
    "video_info = []\n",
    "for vf in video_files:\n",
    "    path = os.path.join(ammunition_dir, vf)\n",
    "    result = subprocess.run([\n",
    "        \"ffprobe\", \"-v\", \"error\", \"-show_entries\",\n",
    "        \"format=duration\", \"-of\", \"default=noprint_wrappers=1:nokey=1\", path\n",
    "    ], capture_output=True)\n",
    "    try:\n",
    "        dur = float(result.stdout.decode().strip())\n",
    "    except Exception:\n",
    "        dur = None\n",
    "    video_info.append((vf, dur))\n",
    "video_options = [\"(無)\"] + [f\"{fn} ({d:.2f}s)\" if d else fn for fn, d in video_info]\n",
    "video_map = {f\"{fn} ({d:.2f}s)\": fn for fn, d in video_info if d}\n",
    "image_options = [\"(無)\"] + image_files\n",
    "\n",
    "audio_durations = [None] * len(valid_sentences)\n",
    "for i in range(len(valid_sentences)):\n",
    "    af = valid_audio_files[i] if i < len(valid_audio_files) else None\n",
    "    if af and os.path.exists(af):\n",
    "        result = subprocess.run([\n",
    "            \"ffprobe\", \"-v\", \"error\", \"-show_entries\",\n",
    "            \"format=duration\", \"-of\", \"default=noprint_wrappers=1:nokey=1\", af\n",
    "        ], capture_output=True)\n",
    "        try:\n",
    "            audio_durations[i] = float(result.stdout.decode().strip())\n",
    "        except Exception:\n",
    "            audio_durations[i] = None\n",
    "accum_durations = []\n",
    "running_total = 0.0\n",
    "for d in audio_durations:\n",
    "    running_total += d if d else 0\n",
    "    accum_durations.append(running_total)\n",
    "\n",
    "sentence_labels = []\n",
    "bg_selectors = []\n",
    "vid_selectors = []\n",
    "bg_preview_btns = []\n",
    "\n",
    "def get_scene_img_for_idx(i):\n",
    "    for idx, (start, end) in enumerate(scene_ranges):\n",
    "        if start <= i < end:\n",
    "            return scene_images[idx] if scene_images[idx] else \"(無)\"\n",
    "    return \"(無)\"\n",
    "\n",
    "for i, sentence in enumerate(valid_sentences):\n",
    "    aud_dur = audio_durations[i] if i < len(audio_durations) and audio_durations[i] else 0\n",
    "    accum_dur = accum_durations[i] if i < len(accum_durations) else 0\n",
    "    label_txt = f\"{i+1}. {sentence[:40]} (audio: {aud_dur:.2f}s, total: {accum_dur:.2f}s)\"\n",
    "    sentence_label = widgets.Label(label_txt)\n",
    "    # 預設背景(初始化時尚未有AI圖)\n",
    "    bg_default = \"(無)\"\n",
    "    bg_dd_options = [\"(無)\"] + image_files\n",
    "    bg_dd = widgets.Dropdown(options=bg_dd_options, value=bg_default, description=\"\")\n",
    "    vid_dd = widgets.Dropdown(options=video_options, value=\"(無)\", description=\"\")\n",
    "    sentence_labels.append(sentence_label)\n",
    "    bg_selectors.append(bg_dd)\n",
    "    vid_selectors.append(vid_dd)\n",
    "    # 預覽按鈕\n",
    "    def preview_fun(img_name=bg_default):\n",
    "        def show(_):\n",
    "            if img_name != \"(無)\":\n",
    "                img_path = os.path.join(subdir, img_name)\n",
    "                if not os.path.exists(img_path):\n",
    "                    img_path = os.path.join(ammunition_dir, img_name)\n",
    "                if os.path.exists(img_path):\n",
    "                    display(IPyImage(filename=img_path))\n",
    "        return show\n",
    "    preview_btn = widgets.Button(description=\"預覽背景\")\n",
    "    preview_btn.on_click(preview_fun(img_name=bg_default))\n",
    "    bg_preview_btns.append(preview_btn)\n",
    "\n",
    "col1_title = widgets.HTML(\"<b>句子 / 時間</b>\")\n",
    "col2_title = widgets.HTML(\"<b>背景圖片</b>\")\n",
    "col3_title = widgets.HTML(\"<b>背景預覽</b>\")\n",
    "col4_title = widgets.HTML(\"<b>影片剪輯</b>\")\n",
    "\n",
    "sentence_labels_col = widgets.VBox([col1_title] + sentence_labels)\n",
    "bg_selectors_col = widgets.VBox([col2_title] + bg_selectors)\n",
    "bg_preview_col  = widgets.VBox([col3_title] + bg_preview_btns)\n",
    "vid_selectors_col = widgets.VBox([col4_title] + vid_selectors)\n",
    "table_ui = widgets.HBox([sentence_labels_col, bg_selectors_col, bg_preview_col, vid_selectors_col])\n",
    "\n",
    "instructions = widgets.HTML(\"\"\"\n",
    "<b>分鏡表編輯器（語意分場景AI背景/手動選檔 + 分句細緻分鏡表 + 預覽功能）</b><br>\n",
    "上方：場景分段字幕、AI背景生成/手動選檔（產生/選擇後自動分配背景，分鏡表即時更新）<br>\n",
    "下方：分句分鏡表可手動調整背景、影片等（預設已依場景分配背景）<br>\n",
    "儲存時背景空白自動沿用上一句設定。\n",
    "\"\"\")\n",
    "\n",
    "display(instructions, table_ui)\n",
    "\n",
    "# --- 4️⃣ 場景UI，沿用/重新產生都能即時填入分鏡表 ---\n",
    "scene_widgets = []\n",
    "for idx, (start, end) in enumerate(scene_ranges):\n",
    "    seg_sentences = valid_sentences[start:end]\n",
    "    seg_text = \"\\n\".join([f\"{i+1}. {s}\" for i, s in enumerate(seg_sentences)])\n",
    "    prompt = f\"Minimalist, modern, unique illustration for a YouTube thumbnail. Scene {idx+1}: {seg_text}\"\n",
    "\n",
    "    label = widgets.HTML(f\"<b>場景{idx+1} 字幕:</b><br><pre>{seg_text}</pre>\")\n",
    "    img_preview = widgets.Output()\n",
    "    img_path_label = widgets.Label(\"尚未選取圖片\")\n",
    "    select_img_dd = widgets.Dropdown(options=[\"(請選擇)\"] + image_files, value=\"(請選擇)\", description=\"\")\n",
    "\n",
    "    def on_gen_clicked(b, idx=idx, prompt=prompt, seg_sentences=seg_sentences, start=start, end=end):\n",
    "        try:\n",
    "            fname = dalle3_generate(prompt, idx, seg_sentences)\n",
    "            scene_images[idx] = fname\n",
    "            scene_img_names[idx] = os.path.basename(fname)\n",
    "            img_preview.clear_output()\n",
    "            img_path_label.value = f\"AI生成：{os.path.basename(fname)}\"\n",
    "            display(IPyImage(filename=fname))\n",
    "            # 分配此場景所有句子的背景（分鏡表即時顯示）\n",
    "            for i in range(start, end):\n",
    "                bg_selectors[i].value = os.path.basename(fname)\n",
    "        except Exception as e:\n",
    "            img_preview.clear_output()\n",
    "            img_path_label.value = f\"生成失敗: {e}\"\n",
    "\n",
    "    def on_select_img_change(change, idx=idx, start=start, end=end):\n",
    "        if change[\"name\"] == \"value\" and change[\"new\"] != \"(請選擇)\":\n",
    "            chosen = change[\"new\"]\n",
    "            scene_images[idx] = os.path.join(ammunition_dir, chosen)\n",
    "            scene_img_names[idx] = chosen\n",
    "            img_preview.clear_output()\n",
    "            img_path_label.value = f\"使用檔案：{chosen}\"\n",
    "            display(IPyImage(filename=os.path.join(ammunition_dir, chosen)))\n",
    "            # 分配此場景所有句子的背景（分鏡表即時顯示）\n",
    "            for i in range(start, end):\n",
    "                bg_selectors[i].value = chosen\n",
    "\n",
    "    select_img_dd.observe(lambda change, idx=idx, start=start, end=end: on_select_img_change(change, idx, start, end), names=\"value\")\n",
    "    btn_gen = widgets.Button(description=\"重新產生\", button_style=\"danger\")\n",
    "    btn_gen.on_click(functools.partial(on_gen_clicked, idx=idx, prompt=prompt, seg_sentences=seg_sentences, start=start, end=end))\n",
    "\n",
    "    seg_box = widgets.VBox([\n",
    "        label,\n",
    "        widgets.HBox([widgets.Label(\"沿用圖片：\"), select_img_dd]),\n",
    "        btn_gen,\n",
    "        img_path_label,\n",
    "        img_preview\n",
    "    ])\n",
    "    scene_widgets.append(seg_box)\n",
    "\n",
    "scene_ui = widgets.VBox(scene_widgets)\n",
    "display(scene_ui)\n",
    "\n",
    "# --- 5️⃣ 儲存分鏡表（自動補齊背景，分鏡欄位全保留）---\n",
    "save_btn = widgets.Button(description=\"儲存分鏡表\", button_style=\"success\")\n",
    "output = widgets.Output()\n",
    "\n",
    "def get_duration(path):\n",
    "    if not os.path.exists(path):\n",
    "        return None\n",
    "    result = subprocess.run([\n",
    "        \"ffprobe\", \"-v\", \"error\", \"-show_entries\",\n",
    "        \"format=duration\", \"-of\", \"default=noprint_wrappers=1:nokey=1\", path\n",
    "    ], capture_output=True)\n",
    "    try:\n",
    "        return float(result.stdout.decode().strip())\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def save_plan(b):\n",
    "    with output:\n",
    "        output.clear_output()\n",
    "        visual_plan = []\n",
    "        warnings = []\n",
    "        # 取得所有背景圖選擇\n",
    "        bg_list = []\n",
    "        for i, bg_dd in enumerate(bg_selectors):\n",
    "            val = bg_dd.value\n",
    "            if val and val != \"(無)\":\n",
    "                f1 = os.path.join(subdir, val)\n",
    "                f2 = os.path.join(ammunition_dir, val)\n",
    "                bg_path = f1 if os.path.exists(f1) else f2 if os.path.exists(f2) else val\n",
    "                bg_list.append(bg_path)\n",
    "            else:\n",
    "                bg_list.append(None)\n",
    "        last_bg = None\n",
    "        for i in range(len(bg_list)):\n",
    "            if bg_list[i] is None and last_bg is not None:\n",
    "                bg_list[i] = last_bg\n",
    "            elif bg_list[i] is not None:\n",
    "                last_bg = bg_list[i]\n",
    "        for i, sentence in enumerate(valid_sentences):\n",
    "            bg = bg_list[i]\n",
    "            vid_label = vid_selectors[i].value\n",
    "            vid = None\n",
    "            vid_dur = None\n",
    "            if vid_label != \"(無)\":\n",
    "                if vid_label in video_map:\n",
    "                    vid = video_map[vid_label]\n",
    "                    vid_dur = get_duration(os.path.join(ammunition_dir, vid))\n",
    "                else:\n",
    "                    vid = vid_label.split(\" (\")[0]\n",
    "                    vid_dur = get_duration(os.path.join(ammunition_dir, vid))\n",
    "            audio_fname = valid_audio_files[i]\n",
    "            audio_dur = audio_durations[i] if i < len(audio_durations) and audio_durations[i] else 0\n",
    "            accum_dur = accum_durations[i] if i < len(accum_durations) else 0\n",
    "            if vid and vid_dur and audio_dur and abs(vid_dur - audio_dur) > 1.0:\n",
    "                warnings.append(f\"⚠️ 句{i+1}影片({vid_dur:.2f}s)與語音({audio_dur:.2f}s)時長不符。\")\n",
    "            visual_plan.append({\n",
    "                \"sentence_idx\": i,\n",
    "                \"sentence\": sentence,\n",
    "                \"audio_file\": audio_fname,\n",
    "                \"audio_duration\": audio_dur,\n",
    "                \"accum_duration\": accum_dur,\n",
    "                \"background\": bg,\n",
    "                \"video_clip\": vid,\n",
    "                \"video_duration\": vid_dur\n",
    "            })\n",
    "        visual_plan_path = os.path.join(subdir, \"visual_plan.yaml\")\n",
    "        with open(visual_plan_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            yaml.safe_dump(visual_plan, f, allow_unicode=True)\n",
    "        print(f\"分鏡表已儲存至 {visual_plan_path}\")\n",
    "        if warnings:\n",
    "            print(\"\\n\".join(warnings))\n",
    "        print(\"前3項：\")\n",
    "        for vp in visual_plan[:3]:\n",
    "            print(vp)\n",
    "\n",
    "save_btn.on_click(save_plan)\n",
    "display(save_btn, output)\n",
    "print(\"=\"*40)\n",
    "print(f\"專案名稱: {config.get('project_title', config.get('title', '未設定'))}\")\n",
    "print(f\"Current subdir: {subdir}\")\n",
    "print(f\"目前工作目錄：{os.getcwd()}\")\n",
    "print(\"=\"*40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c47431-2efa-4767-8ced-d29da5e485d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "import datetime\n",
    "import re\n",
    "from snownlp import SnowNLP\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "from dotenv import load_dotenv\n",
    "import subprocess\n",
    "\n",
    "print(\"=== STEP 0: 專案資料 ===\")\n",
    "main_dir = os.getcwd()\n",
    "with open('config.yaml', encoding='utf-8') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "project_title = config.get('project_title', config.get('title', 'My YouTube Video'))\n",
    "today = datetime.datetime.now().strftime(\"%Y%m%d\")\n",
    "safe_title = re.sub(r'[\\\\/:*?\"<>|\\n\\r\\t]', '', project_title)[:20]\n",
    "subdir = os.path.join(main_dir, f\"{today}_{safe_title}\")\n",
    "ammunition_dir = os.path.join(main_dir, \"ammunition\")\n",
    "text_file = os.path.join(ammunition_dir, config.get('text', 'text.txt'))\n",
    "input_text = config.get('input_text', '')\n",
    "\n",
    "print(\"Current subdir (引用):\", subdir)\n",
    "print(\"目前工作目錄：\", os.getcwd())\n",
    "print(\"資源目錄(ammunition):\", ammunition_dir)\n",
    "\n",
    "# 更新 text.txt\n",
    "with open(text_file, 'w', encoding='utf-8') as f:\n",
    "    f.write(input_text)\n",
    "\n",
    "# 句子分割\n",
    "def is_pronounceable(s):\n",
    "    return bool(re.search(r'[\\u4e00-\\u9fffA-Za-z0-9]', s))\n",
    "def clean_markdown(s):\n",
    "    s = re.sub(r\"^[#\\-*\\s>]+\", \"\", s)\n",
    "    s = re.sub(r\"(\\*|`|_|>|#|\\[|\\]|\\(|\\)|\\-|~|=|>)\", \"\", s)\n",
    "    s = re.sub(r\"[「」]\", \"\", s)\n",
    "    s = re.sub(r\"\\s+\", \" \", s)\n",
    "    return s.strip()\n",
    "try:\n",
    "    with open(text_file, encoding=\"utf-8\") as f:\n",
    "        text = f.read().strip()\n",
    "    sentences = [s.strip() for s in SnowNLP(text).sentences if s.strip()]\n",
    "except Exception as e:\n",
    "    print(f\"[ERROR] SnowNLP sentence segmentation failed: {e}\")\n",
    "    sentences = [text] if text else []\n",
    "sentences = [clean_markdown(s) for s in sentences if is_pronounceable(s)]\n",
    "sentences = [s for s in sentences if is_pronounceable(s)]\n",
    "print(f\"Total sentences after filtering: {len(sentences)}\")\n",
    "\n",
    "print(\"\\n=== STEP 1: TTS語音合成 ===\")\n",
    "load_dotenv()\n",
    "tts_server = config.get('tts_server', 'azure')\n",
    "audio_files = []\n",
    "failed_sentences = []\n",
    "\n",
    "tts_files_exist = True\n",
    "for i in range(len(sentences)):\n",
    "    fname = os.path.join(subdir, f\"voice_{i}.mp3\")\n",
    "    if not (os.path.exists(fname) and os.path.getsize(fname) > 0):\n",
    "        tts_files_exist = False\n",
    "        break\n",
    "\n",
    "if tts_files_exist:\n",
    "    choice = widgets.ToggleButtons(\n",
    "        options=['全部跳過', '全部重新TTS'],\n",
    "        description='所有語音檔已存在，是否要全部重新TTS？',\n",
    "        style={'description_width': 'initial'}\n",
    "    )\n",
    "    output = widgets.Output()\n",
    "    display(choice, output)\n",
    "    def synthesize_all_tts():\n",
    "        global audio_files, failed_sentences\n",
    "        audio_files = []\n",
    "        failed_sentences = []\n",
    "        if tts_server == 'azure':\n",
    "            import azure.cognitiveservices.speech as speechsdk\n",
    "            AZURE_SPEECH_KEY = os.environ.get(\"AZURE_SPEECH_KEY\")\n",
    "            AZURE_SPEECH_REGION = os.environ.get(\"AZURE_SPEECH_REGION\")\n",
    "            VOICE = config.get('azure_voice', 'zh-TW-YunJheNeural')\n",
    "            print(f\"[CHECK] Azure voice_id (voice_name) used for synthesis: {VOICE}\")\n",
    "            for i, sentence in enumerate(sentences):\n",
    "                mp3_fname = os.path.join(subdir, f\"voice_{i}.mp3\")\n",
    "                speech_config = speechsdk.SpeechConfig(subscription=AZURE_SPEECH_KEY, region=AZURE_SPEECH_REGION)\n",
    "                speech_config.speech_synthesis_voice_name = VOICE\n",
    "                speech_config.set_speech_synthesis_output_format(\n",
    "                    speechsdk.SpeechSynthesisOutputFormat.Audio16Khz32KBitRateMonoMp3\n",
    "                )\n",
    "                audio_config = speechsdk.audio.AudioOutputConfig(filename=mp3_fname)\n",
    "                synthesizer = speechsdk.SpeechSynthesizer(speech_config=speech_config, audio_config=audio_config)\n",
    "                result = synthesizer.speak_text_async(sentence).get()\n",
    "                if result.reason == speechsdk.ResultReason.SynthesizingAudioCompleted:\n",
    "                    print(f\"[OK] 合成完成: {mp3_fname}\")\n",
    "                    audio_files.append(mp3_fname)\n",
    "                elif result.reason == speechsdk.ResultReason.Canceled:\n",
    "                    cancellation_details = speechsdk.CancellationDetails(result)\n",
    "                    print(f\"[ERROR] 合成失敗: {sentence}\")\n",
    "                    print(f\"Reason: {cancellation_details.reason}\")\n",
    "                    print(f\"Details: {cancellation_details.error_details}\")\n",
    "                    failed_sentences.append((i, sentence))\n",
    "                else:\n",
    "                    print(f\"[ERROR] TTS失敗(未知): {sentence}, Reason: {result.reason}\")\n",
    "                    failed_sentences.append((i, sentence))\n",
    "        elif tts_server == 'minimax':\n",
    "            import requests\n",
    "            MINIMAX_SPEECH_KEY = os.environ.get(\"MINIMAX_SPEECH_KEY\")\n",
    "            MINIMAX_URL = \"https://api.minimax.io/v1/t2a_v2?GroupId=1982992498867311582\"\n",
    "            MODEL = config.get(\"minimax_model\", \"speech-02-hd\")\n",
    "            VOICE = config.get(\"minimax_voice\", \"Chinese (Mandarin)_Warm_Bestie\")\n",
    "            EMOTION = config.get(\"minimax_emotion\", \"calm\")\n",
    "            VOL = config.get(\"minimax_vol\", 1.0)\n",
    "            SPEED = config.get(\"minimax_speed\", 1.0)\n",
    "            PITCH = config.get(\"minimax_pitch\", 0)\n",
    "            AUDIO_FORMAT = config.get(\"minimax_audio_format\", \"mp3\")\n",
    "            SAMPLE_RATE = config.get(\"minimax_sample_rate\", 32000)\n",
    "            BITRATE = config.get(\"minimax_bitrate\", 128000)\n",
    "            CHANNEL = config.get(\"minimax_channel\", 1)\n",
    "            headers = {\n",
    "                \"Authorization\": f\"Bearer {MINIMAX_SPEECH_KEY}\",\n",
    "                \"Content-Type\": \"application/json\"\n",
    "            }\n",
    "            print(f\"[CHECK] MINIMAX voice_id (voice_name) used for synthesis: {VOICE}\")\n",
    "            for i, sentence in enumerate(sentences):\n",
    "                fname = os.path.join(subdir, f\"voice_{i}.{AUDIO_FORMAT}\")\n",
    "                payload = {\n",
    "                    \"model\": MODEL,\n",
    "                    \"text\": sentence,\n",
    "                    \"voice_setting\": {\n",
    "                        \"voice_id\": VOICE,\n",
    "                        \"speed\": SPEED,\n",
    "                        \"vol\": VOL,\n",
    "                        \"pitch\": PITCH,\n",
    "                        \"emotion\": EMOTION\n",
    "                    },\n",
    "                    \"audio_setting\": {\n",
    "                        \"sample_rate\": SAMPLE_RATE,\n",
    "                        \"bitrate\": BITRATE,\n",
    "                        \"format\": AUDIO_FORMAT,\n",
    "                        \"channel\": CHANNEL\n",
    "                    },\n",
    "                    \"output_format\": \"url\",\n",
    "                    \"language_boost\": \"auto\",\n",
    "                    \"subtitle_enable\": False\n",
    "                }\n",
    "                r = requests.post(MINIMAX_URL, headers=headers, json=payload)\n",
    "                if r.status_code == 200:\n",
    "                    data = r.json()\n",
    "                    base_resp = data.get(\"base_resp\", {})\n",
    "                    if base_resp.get(\"status_code\") == 0:\n",
    "                        audio_url = data.get(\"data\", {}).get(\"audio\")\n",
    "                        if audio_url:\n",
    "                            r2 = requests.get(audio_url)\n",
    "                            if r2.status_code == 200:\n",
    "                                with open(fname, \"wb\") as f:\n",
    "                                    f.write(r2.content)\n",
    "                                print(f\"[OK] MINIMAX合成完成: {fname}\")\n",
    "                                audio_files.append(fname)\n",
    "                            else:\n",
    "                                print(f\"[ERROR] MINIMAX音檔下載失敗: {r2.status_code}\")\n",
    "                                failed_sentences.append((i, sentence))\n",
    "                        else:\n",
    "                            print(f\"[ERROR] MINIMAX未取得音檔URL: {data}\")\n",
    "                            failed_sentences.append((i, sentence))\n",
    "                    else:\n",
    "                        print(f\"[ERROR] MINIMAX API錯誤: {base_resp.get('status_msg', '')}\")\n",
    "                        failed_sentences.append((i, sentence))\n",
    "                else:\n",
    "                    print(f\"[ERROR] MINIMAX TTS API HTTP錯誤: {r.status_code}\")\n",
    "                    failed_sentences.append((i, sentence))\n",
    "        else:\n",
    "            print(\"[ERROR] 未支援的 TTS server 設定：\", tts_server)\n",
    "        print(\"TTS synthesis complete. Valid files:\", len(audio_files))\n",
    "        if failed_sentences:\n",
    "            print(\"Failed sentences:\")\n",
    "            for idx, s in failed_sentences:\n",
    "                print(f\"Sentence {idx}: '{s}'\")\n",
    "        else:\n",
    "            print(\"所有語音檔已重新生成完成。\")\n",
    "\n",
    "    def on_choice_change(change):\n",
    "        if change['name'] == 'value':\n",
    "            with output:\n",
    "                clear_output()\n",
    "                if change['new'] == '全部跳過':\n",
    "                    print(\"已選擇跳過語音合成，全部僅引用 subdir 下現有檔案。\")\n",
    "                else:\n",
    "                    print(\"開始重新TTS生成所有語音...\")\n",
    "                    synthesize_all_tts()\n",
    "    choice.observe(on_choice_change, names='value')\n",
    "else:\n",
    "    print(\"部分語音檔不存在，將直接生成缺漏語音檔...\")\n",
    "    # 直接補齊缺漏語音檔（可複製 synthesize_all_tts() 內容，但僅補缺漏檔案）\n",
    "\n",
    "print(\"\\n=== STEP 2: 合併語音檔 ===\")\n",
    "voice_list = [os.path.join(subdir, f\"voice_{i}.mp3\") for i in range(len(sentences))]\n",
    "valid_voice_list = [f for f in voice_list if os.path.exists(f) and os.path.getsize(f) > 0]\n",
    "concat_list_path = os.path.join(subdir, \"voice_list.txt\")\n",
    "with open(concat_list_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    for vf in valid_voice_list:\n",
    "        f.write(f\"file '{vf}'\\n\")\n",
    "concat_voice_path = os.path.join(subdir, \"voice.mp3\")\n",
    "subprocess.run([\n",
    "    \"ffmpeg\", \"-y\", \"-f\", \"concat\", \"-safe\", \"0\",\n",
    "    \"-i\", concat_list_path, \"-c\", \"copy\", concat_voice_path\n",
    "])\n",
    "print(\"合併完成:\", concat_voice_path)\n",
    "\n",
    "print(\"\\n=== STEP 3: 產生字幕檔 (.srt) ===\")\n",
    "# 假設每句字幕時間依語音長度（需安裝ffprobe），也可簡單估算每句2秒\n",
    "srt_path = os.path.join(subdir, \"subtitle.srt\")\n",
    "start_time = 0.0\n",
    "with open(srt_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    for idx, vf in enumerate(valid_voice_list):\n",
    "        # 取得每句語音長度\n",
    "        result = subprocess.run([\n",
    "            \"ffprobe\", \"-v\", \"error\", \"-show_entries\",\n",
    "            \"format=duration\", \"-of\", \"default=noprint_wrappers=1:nokey=1\", vf\n",
    "        ], capture_output=True)\n",
    "        try:\n",
    "            dur = float(result.stdout.decode().strip())\n",
    "        except Exception:\n",
    "            dur = 2.0\n",
    "        end_time = start_time + dur\n",
    "        st = \"%02d:%02d:%06.3f\" % (int(start_time//3600), int((start_time%3600)//60), start_time%60)\n",
    "        et = \"%02d:%02d:%06.3f\" % (int(end_time//3600), int((end_time%3600)//60), end_time%60)\n",
    "        # SRT格式: hh:mm:ss,ms\n",
    "        st_srt = \"%02d:%02d:%02d,%03d\" % (int(start_time//3600), int((start_time%3600)//60), int(start_time%60), int((start_time%1)*1000))\n",
    "        et_srt = \"%02d:%02d:%02d,%03d\" % (int(end_time//3600), int((end_time%3600)//60), int(end_time%60), int((end_time%1)*1000))\n",
    "        f.write(f\"{idx+1}\\n{st_srt} --> {et_srt}\\n{sentences[idx]}\\n\\n\")\n",
    "        start_time = end_time\n",
    "print(\"字幕檔完成:\", srt_path)\n",
    "\n",
    "print(\"\\n=== STEP 4: 合成配樂 ===\")\n",
    "bgm_file = os.path.join(ammunition_dir, config.get('bgm', 'bgm.mp3'))\n",
    "bgm_volume = float(config.get('bgm_volume', 0.3))\n",
    "voice_with_bgm_path = os.path.join(subdir, \"voice_bgm.mp3\")\n",
    "subprocess.run([\n",
    "    \"ffmpeg\", \"-y\",\n",
    "    \"-i\", concat_voice_path,\n",
    "    \"-i\", bgm_file,\n",
    "    \"-filter_complex\", f\"[1:a]volume={bgm_volume}[bgm];[0:a][bgm]amix=inputs=2:duration=first:dropout_transition=3\",\n",
    "    \"-c:a\", \"mp3\",\n",
    "    voice_with_bgm_path\n",
    "])\n",
    "print(\"語音+配樂合成完成:\", voice_with_bgm_path)\n",
    "\n",
    "from IPython.display import clear_output\n",
    "clear_output(wait=True)\n",
    "\n",
    "import shutil\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "print(\"\\n=== STEP 5: 產生影片（全部搬到主程式目錄） ===\")\n",
    "\n",
    "main_dir = os.getcwd()\n",
    "\n",
    "# 檔案來源\n",
    "background_file_src = os.path.join(subdir, \"background.jpg\")\n",
    "voice_with_bgm_path_src = os.path.join(subdir, \"voice_bgm.mp3\")\n",
    "srt_path_src = os.path.join(subdir, \"subtitle.srt\")\n",
    "\n",
    "# 檢查檔案\n",
    "for fname in [\"background.jpg\", \"voice_bgm.mp3\", \"subtitle.srt\"]:\n",
    "    fpath = os.path.join(subdir, fname)\n",
    "    print(f\"{fname}: {os.path.exists(fpath)} ({fpath})\")\n",
    "\n",
    "if not os.path.exists(background_file_src):\n",
    "    source_bg = os.path.join(ammunition_dir, config.get('background', 'background.jpg'))\n",
    "    if os.path.exists(source_bg):\n",
    "        shutil.copy2(source_bg, background_file_src)\n",
    "        print(\"補上 background.jpg 到 subdir\")\n",
    "\n",
    "# 搬檔到主程式目錄（只搬有的）\n",
    "for src, dst in [\n",
    "    (background_file_src, os.path.join(main_dir, \"background.jpg\")),\n",
    "    (voice_with_bgm_path_src, os.path.join(main_dir, \"voice_bgm.mp3\")),\n",
    "    (srt_path_src, os.path.join(main_dir, \"subtitle.srt\"))\n",
    "]:\n",
    "    if os.path.exists(src):\n",
    "        shutil.copy2(src, dst)\n",
    "    else:\n",
    "        print(f\"缺少檔案：{src}，請先確認流程前面已正確產生。\")\n",
    "\n",
    "video_resolution = config.get('video_resolution', '1920,1080')\n",
    "width, height = map(int, video_resolution.split(','))\n",
    "\n",
    "cmd = [\n",
    "    \"ffmpeg\", \"-y\",\n",
    "    \"-loop\", \"1\", \"-i\", \"background.jpg\",\n",
    "    \"-i\", \"voice_bgm.mp3\",\n",
    "    \"-vf\", f\"scale={width}:{height},subtitles=subtitle.srt\",\n",
    "    \"-shortest\",\n",
    "    \"-c:v\", \"libx264\", \"-c:a\", \"aac\",\n",
    "    \"-b:a\", \"192k\",\n",
    "    \"final.mp4\"\n",
    "]\n",
    "print(\"執行指令：\", \" \".join(cmd))\n",
    "\n",
    "result = subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, cwd=main_dir)\n",
    "print(\"ffmpeg stdout:\", result.stdout.decode('utf-8', errors='ignore'))\n",
    "print(\"ffmpeg stderr:\", result.stderr.decode('utf-8', errors='ignore'))\n",
    "\n",
    "final_mp4_file = os.path.join(main_dir, \"final.mp4\")\n",
    "final_mp4_dst = os.path.join(subdir, \"final.mp4\")\n",
    "if os.path.exists(final_mp4_file):\n",
    "    shutil.copy2(final_mp4_file, final_mp4_dst)\n",
    "    print(\"影片合成完成:\", final_mp4_dst)\n",
    "    print(\"影片複本已保留於:\", final_mp4_file)\n",
    "else:\n",
    "    print(\"影片合成失敗，請檢查錯誤訊息。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641edc41-0890-4418-804a-9d146414e649",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c19dd59-d749-449c-944d-64edf332f785",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45307db5-ffdf-451a-bffd-2ee859aa256b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238faa31-3229-4f9c-a552-4a679d283ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 8.2\n",
    "\n",
    "import os\n",
    "import openai\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "from IPython.display import display, Image as IPyImage, FileLink\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# 讀取 .env，取得 OPENAI_API\n",
    "load_dotenv()\n",
    "openai.api_key = os.getenv(\"OPENAI_API\")\n",
    "\n",
    "# 讀取 text.txt 劇本\n",
    "text_path = os.path.join(ammunition_dir, \"text.txt\")\n",
    "with open(text_path, encoding=\"utf-8\") as f:\n",
    "    script_text = f.read().strip()\n",
    "\n",
    "# 1️⃣ 劇本自動斷句分鏡（最多4場景）\n",
    "def auto_split_script(text, max_scene=4):\n",
    "    lines = [l.strip() for l in text.split('\\n') if l.strip()]\n",
    "    n = min(max_scene, len(lines))\n",
    "    if n == 1: return [text]\n",
    "    chunk_len = len(lines) // n if len(lines) >= n else 1\n",
    "    scenes = []\n",
    "    for i in range(n):\n",
    "        start = i * chunk_len\n",
    "        end = (i+1) * chunk_len if i < n-1 else len(lines)\n",
    "        scene = ' '.join(lines[start:end])\n",
    "        if scene: scenes.append(scene)\n",
    "    return scenes[:max_scene]\n",
    "\n",
    "scenes = auto_split_script(script_text, max_scene=4)\n",
    "print(f\"自動分割為 {len(scenes)} 個場景。\")\n",
    "\n",
    "# 2️⃣ 為每個場景生成獨特的簡約風繪圖 prompt\n",
    "def make_prompt(scene, idx):\n",
    "    # 強化簡約、獨特、現代感與YouTube縮圖規格\n",
    "    return (\n",
    "        f\"Minimalist, modern, unique illustration for a YouTube thumbnail, \"\n",
    "        f\"1920x1080, clean design, simple shapes, flat colors, high contrast. \"\n",
    "        f\"Scene {idx+1}: {scene}. The image should be visually striking and creative.\"\n",
    "    )\n",
    "\n",
    "prompts = [make_prompt(scene, i) for i, scene in enumerate(scenes)]\n",
    "\n",
    "# 3️⃣ 呼叫 OPENAI DALL·E 3 API 產生影像，預覽與下載\n",
    "def dalle3_generate(prompt, idx, size=\"1920x1080\"):\n",
    "    print(f\"呼叫DALL·E生成場景{idx+1}...\")\n",
    "    response = openai.images.generate(\n",
    "        model=\"dall-e-3\",\n",
    "        prompt=prompt,\n",
    "        size=size,\n",
    "        n=1,\n",
    "        quality=\"standard\"\n",
    "    )\n",
    "    url = response.data[0].url\n",
    "    imgdata = requests.get(url).content\n",
    "    fname = os.path.join(subdir, f\"scene_{idx+1}.jpg\")\n",
    "    with open(fname, \"wb\") as f:\n",
    "        f.write(imgdata)\n",
    "    img = Image.open(BytesIO(imgdata))\n",
    "    display(IPyImage(data=imgdata, format='jpeg'))\n",
    "    print(f\"已儲存場景{idx+1}圖片：{fname}\")\n",
    "    return fname\n",
    "\n",
    "scene_images = []\n",
    "for idx, prompt in enumerate(prompts):\n",
    "    print(f\"場景{idx+1} prompt：{prompt}\")\n",
    "    fname = dalle3_generate(prompt, idx)\n",
    "    scene_images.append(fname)\n",
    "\n",
    "print(\"\\n下載圖片：\")\n",
    "for fname in scene_images:\n",
    "    display(FileLink(fname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c87cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 15\n",
    "print(\"專案名稱:\", config.get(\"project_title\", config.get(\"title\", \"未設定\")))\n",
    "print(\"Current subdir:\", subdir)\n",
    "print(\"目前工作目錄：\", os.getcwd())\n",
    "\n",
    "from IPython.display import Video as ShowVideo, Image as ShowImage\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# --- Use consistent variables and paths ---\n",
    "project_title = config.get('project_title', config.get('title', 'test'))\n",
    "project_author = config.get('project_author', config.get('author', '未設定'))\n",
    "attribution = config.get('attribution', '')\n",
    "thumbnail_name = config.get('thumbnail', 'thumbnail.jpg')\n",
    "thumbnail_path = os.path.join(subdir, thumbnail_name)\n",
    "\n",
    "final_video_name = f\"final_{project_title}.mp4\"\n",
    "outname_final = os.path.join(main_dir, final_video_name)\n",
    "\n",
    "# --- Display thumbnail and final video ---\n",
    "if os.path.exists(thumbnail_path):\n",
    "    display(ShowImage(thumbnail_path))\n",
    "else:\n",
    "    print(f\"Thumbnail not found: {thumbnail_path}\")\n",
    "\n",
    "if os.path.exists(outname_final):\n",
    "    display(ShowVideo(url=outname_final))\n",
    "else:\n",
    "    print(f\"Final video not found: {outname_final}\")\n",
    "\n",
    "# --- Export YouTube metadata ---\n",
    "youtube_metadata_path = os.path.join(subdir, \"youtube_metadata.txt\")\n",
    "subtitle_srt_path = os.path.join(subdir, \"subtitle.srt\")  # ASS to SRT conversion not shown, but path reserved\n",
    "dt_utc_now = datetime.utcnow() + timedelta(hours=8)\n",
    "\n",
    "with open(youtube_metadata_path, \"w\", encoding=\"utf-8\") as meta:\n",
    "    meta.write(f\"Title: {project_title}\\n\")\n",
    "    meta.write(f\"Author: {project_author}\\n\")\n",
    "    meta.write(f\"Date: {dt_utc_now.strftime('%Y-%m-%d')}\\n\")\n",
    "    meta.write(f\"Description: {attribution}\\n\")\n",
    "    meta.write(f\"Subtitle SRT: {subtitle_srt_path}\\n\")\n",
    "    meta.write(f\"Thumbnail: {thumbnail_path}\\n\")\n",
    "\n",
    "print(f\"Exported metadata for YouTube upload: {youtube_metadata_path}\")\n",
    "print(\"=\"*40)\n",
    "print(f\"專案名稱: {project_title}\")\n",
    "print(f\"Current subdir: {subdir}\")\n",
    "print(f\"目前工作目錄：{os.getcwd()}\")\n",
    "print(\"=\"*40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0fd38c-80f9-4b35-b928-517e8a78bafc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655e45d6-57a0-4e04-bcc5-2672bb14710d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 8.2\n",
    "\n",
    "import os\n",
    "import openai\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "from IPython.display import display, Image as IPyImage, FileLink\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# 讀取 .env，取得 OPENAI_API\n",
    "load_dotenv()\n",
    "openai.api_key = os.getenv(\"OPENAI_API\")\n",
    "\n",
    "text_path = os.path.join(ammunition_dir, \"text.txt\")\n",
    "with open(text_path, encoding=\"utf-8\") as f:\n",
    "    script_text = f.read().strip()\n",
    "\n",
    "def auto_split_script(text, max_scene=4):\n",
    "    lines = [l.strip() for l in text.split('\\n') if l.strip()]\n",
    "    n = min(max_scene, len(lines))\n",
    "    if n == 1: return [text]\n",
    "    chunk_len = len(lines) // n if len(lines) >= n else 1\n",
    "    scenes = []\n",
    "    for i in range(n):\n",
    "        start = i * chunk_len\n",
    "        end = (i+1) * chunk_len if i < n-1 else len(lines)\n",
    "        scene = ' '.join(lines[start:end])\n",
    "        if scene: scenes.append(scene)\n",
    "    return scenes[:max_scene]\n",
    "\n",
    "scenes = auto_split_script(script_text, max_scene=4)\n",
    "print(f\"自動分割為 {len(scenes)} 個場景。\")\n",
    "\n",
    "def make_prompt(scene, idx):\n",
    "    return (\n",
    "        f\"Minimalist, modern, unique illustration for a YouTube thumbnail. \"\n",
    "        f\"Scene {idx+1}: {scene}. Flat color, simple composition, high contrast. \"\n",
    "        f\"1920x1080 ratio, striking and creative.\"\n",
    "    )\n",
    "\n",
    "prompts = [make_prompt(scene, i) for i, scene in enumerate(scenes)]\n",
    "\n",
    "def dalle3_generate(prompt, idx, size=\"1792x1024\"):  # 用 DALL·E 支援的最大橫幅\n",
    "    print(f\"呼叫DALL·E生成場景{idx+1}...\")\n",
    "    response = openai.images.generate(\n",
    "        model=\"dall-e-3\",\n",
    "        prompt=prompt,\n",
    "        size=size,         # 支援 '1024x1024', '1024x1792', '1792x1024'\n",
    "        n=1,\n",
    "        quality=\"standard\"\n",
    "    )\n",
    "    url = response.data[0].url\n",
    "    imgdata = requests.get(url).content\n",
    "    img = Image.open(BytesIO(imgdata))\n",
    "    # Resize 成 1920x1080\n",
    "    img_resized = img.resize((1920, 1080), resample=Image.LANCZOS)\n",
    "    fname = os.path.join(subdir, f\"scene_{idx+1}.jpg\")\n",
    "    img_resized.save(fname, format=\"JPEG\")\n",
    "    display(IPyImage(data=BytesIO(img_resized.tobytes()).getvalue(), format='jpeg'))\n",
    "    print(f\"已儲存場景{idx+1}圖片：{fname}\")\n",
    "    return fname\n",
    "\n",
    "scene_images = []\n",
    "for idx, prompt in enumerate(prompts):\n",
    "    print(f\"場景{idx+1} prompt：{prompt}\")\n",
    "    fname = dalle3_generate(prompt, idx)\n",
    "    scene_images.append(fname)\n",
    "\n",
    "print(\"\\n下載圖片：\")\n",
    "for fname in scene_images:\n",
    "    display(FileLink(fname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd4116d6-1217-4d4f-92c8-c67c380658a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import azure.cognitiveservices.speech as speechsdk\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# 讀取 .env\n",
    "load_dotenv()\n",
    "AZURE_SPEECH_KEY = os.environ.get(\"AZURE_SPEECH_KEY\")\n",
    "AZURE_SPEECH_REGION = os.environ.get(\"AZURE_SPEECH_REGION\")\n",
    "VOICE = \"zh-TW-YunJheNeural\"\n",
    "SPEED = 1.0\n",
    "PITCH = 0\n",
    "\n",
    "def azure_tts_api(text, voice, speed, pitch):\n",
    "    speech_config = speechsdk.SpeechConfig(subscription=AZURE_SPEECH_KEY, region=AZURE_SPEECH_REGION)\n",
    "    speech_config.speech_synthesis_voice_name = voice\n",
    "    synthesizer = speechsdk.SpeechSynthesizer(speech_config=speech_config)\n",
    "    result = synthesizer.speak_text_async(text).get()\n",
    "    if result.reason == speechsdk.ResultReason.Canceled:\n",
    "        cancellation_details = speechsdk.CancellationDetails(result)\n",
    "        print(f\"Azure TTS失敗: {cancellation_details.reason}\\n{cancellation_details.error_details}\")\n",
    "        return None\n",
    "    if result.reason == speechsdk.ResultReason.SynthesizingAudioCompleted:\n",
    "        import tempfile\n",
    "        tf = tempfile.NamedTemporaryFile(delete=False, suffix='.wav')\n",
    "        tf.write(result.audio_data)\n",
    "        tf.close()\n",
    "        print(f\"合成完成 (preview): {tf.name}\")\n",
    "        return tf.name\n",
    "    else:\n",
    "        print(f\"Azure TTS失敗: {getattr(result, 'error_details', str(result.reason))}\")\n",
    "    return None\n",
    "\n",
    "def azure_tts_to_file(text, voice, speed, pitch, filename):\n",
    "    speech_config = speechsdk.SpeechConfig(subscription=AZURE_SPEECH_KEY, region=AZURE_SPEECH_REGION)\n",
    "    speech_config.speech_synthesis_voice_name = voice\n",
    "    speech_config.set_speech_synthesis_output_format(\n",
    "        speechsdk.SpeechSynthesisOutputFormat.Audio16Khz32KBitRateMonoMp3\n",
    "    )\n",
    "    audio_config = speechsdk.audio.AudioOutputConfig(filename=filename)\n",
    "    synthesizer = speechsdk.SpeechSynthesizer(speech_config=speech_config, audio_config=audio_config)\n",
    "    ssml = f\"\"\"<speak version='1.0' xml:lang='zh-TW'>\n",
    "      <voice name='{voice}'>\n",
    "        <prosody rate='{speed}' pitch='{pitch}'>{text}</prosody>\n",
    "      </voice>\n",
    "    </speak>\"\"\"\n",
    "    result = synthesizer.speak_ssml_async(ssml).get()\n",
    "    if result.reason == speechsdk.ResultReason.SynthesizingAudioCompleted:\n",
    "        print(f\"[OK] 批次合成完成: {filename}\")\n",
    "        return True\n",
    "    elif result.reason == speechsdk.ResultReason.Canceled:\n",
    "        cancellation_details = speechsdk.CancellationDetails(result)\n",
    "        print(f\"[ERROR] 批次合成失敗: {filename}\")\n",
    "        print(f\"Reason: {cancellation_details.reason}\")\n",
    "        print(f\"Details: {cancellation_details.error_details}\")\n",
    "        print(f\"SSML: {ssml}\")\n",
    "        return False\n",
    "    else:\n",
    "        print(f\"[ERROR] TTS失敗(未知): {filename}, Reason: {result.reason}\")\n",
    "        return False\n",
    "\n",
    "# ----------- 測試 preview (cell3) -----------\n",
    "print(\"=== PREVIEW 測試 ===\")\n",
    "azure_tts_api(\"專案名稱為 test\", VOICE, SPEED, PITCH)\n",
    "\n",
    "# ----------- 批次合成 (cell4-8) -----------\n",
    "print(\"=== 批次合成測試 ===\")\n",
    "sentences = [\n",
    "    \"專案名稱為 test\",\n",
    "    \"請在專案開始前確認填寫正確名稱\"\n",
    "]\n",
    "output_dir = \"tts_batch_test\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "for idx, sentence in enumerate(sentences):\n",
    "    fname = os.path.join(output_dir, f\"voice_{idx}.mp3\")\n",
    "    azure_tts_to_file(sentence, VOICE, SPEED, PITCH, fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114cc549-c501-4f19-9be8-f4293e28069b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import azure.cognitiveservices.speech as speechsdk\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "AZURE_SPEECH_KEY = os.environ.get(\"AZURE_SPEECH_KEY\")\n",
    "AZURE_SPEECH_REGION = os.environ.get(\"AZURE_SPEECH_REGION\")\n",
    "VOICE = \"zh-TW-YunJheNeural\"\n",
    "\n",
    "output_dir = \"tts_batch_test\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "for idx, sentence in enumerate([\n",
    "    \"專案名稱為 test\",\n",
    "    \"請在專案開始前確認填寫正確名稱\"\n",
    "]):\n",
    "    speech_config = speechsdk.SpeechConfig(subscription=AZURE_SPEECH_KEY, region=AZURE_SPEECH_REGION)\n",
    "    speech_config.speech_synthesis_voice_name = VOICE\n",
    "    speech_config.set_speech_synthesis_output_format(\n",
    "        speechsdk.SpeechSynthesisOutputFormat.Audio16Khz32KBitRateMonoMp3\n",
    "    )\n",
    "    fname = os.path.join(output_dir, f\"voice_{idx}.mp3\")\n",
    "    audio_config = speechsdk.audio.AudioOutputConfig(filename=fname)\n",
    "    synthesizer = speechsdk.SpeechSynthesizer(speech_config=speech_config, audio_config=audio_config)\n",
    "    result = synthesizer.speak_text_async(sentence).get()\n",
    "    if result.reason == speechsdk.ResultReason.SynthesizingAudioCompleted:\n",
    "        print(f\"[OK] 批次合成完成: {fname}\")\n",
    "    elif result.reason == speechsdk.ResultReason.Canceled:\n",
    "        cancellation_details = speechsdk.CancellationDetails(result)\n",
    "        print(f\"[ERROR] 批次合成失敗: {sentence}\")\n",
    "        print(f\"Reason: {cancellation_details.reason}\")\n",
    "        print(f\"Details: {cancellation_details.error_details}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965904eb-a369-4ed4-8477-322129fecfce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "import tempfile\n",
    "\n",
    "# 讀取 .env\n",
    "load_dotenv()\n",
    "MINIMAX_SPEECH_KEY = os.environ.get(\"MINIMAX_SPEECH_KEY\")\n",
    "\n",
    "# 基本參數\n",
    "MINIMAX_URL = \"https://api.minimax.io/v1/t2a_v2?GroupId=1982992498867311582\"\n",
    "MODEL = \"speech-02-hd\"\n",
    "VOICE = \"Chinese (Mandarin)_Warm_Bestie\"\n",
    "EMOTION = \"calm\"\n",
    "VOL = 1.0\n",
    "SPEED = 1.0\n",
    "PITCH = 0\n",
    "AUDIO_FORMAT = \"mp3\"\n",
    "SAMPLE_RATE = 32000\n",
    "BITRATE = 128000\n",
    "CHANNEL = 1\n",
    "\n",
    "sentence = \"專案名稱為 test\"\n",
    "\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {MINIMAX_SPEECH_KEY}\",\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "payload = {\n",
    "    \"model\": MODEL,\n",
    "    \"text\": sentence,\n",
    "    \"voice_setting\": {\n",
    "        \"voice_id\": VOICE,\n",
    "        \"speed\": SPEED,\n",
    "        \"vol\": VOL,\n",
    "        \"pitch\": PITCH,\n",
    "        \"emotion\": EMOTION\n",
    "    },\n",
    "    \"audio_setting\": {\n",
    "        \"sample_rate\": SAMPLE_RATE,\n",
    "        \"bitrate\": BITRATE,\n",
    "        \"format\": AUDIO_FORMAT,\n",
    "        \"channel\": CHANNEL\n",
    "    },\n",
    "    \"output_format\": \"url\",\n",
    "    \"language_boost\": \"auto\",\n",
    "    \"subtitle_enable\": False\n",
    "}\n",
    "\n",
    "print(\"MINIMAX TTS測試 payload:\")\n",
    "print(payload)\n",
    "\n",
    "r = requests.post(MINIMAX_URL, headers=headers, json=payload)\n",
    "if r.status_code == 200:\n",
    "    data = r.json()\n",
    "    base_resp = data.get(\"base_resp\", {})\n",
    "    if base_resp.get(\"status_code\") == 0:\n",
    "        audio_url = data.get(\"data\", {}).get(\"audio\")\n",
    "        print(\"音檔URL:\", audio_url)\n",
    "        if audio_url:\n",
    "            r2 = requests.get(audio_url)\n",
    "            if r2.status_code == 200:\n",
    "                tf = tempfile.NamedTemporaryFile(delete=False, suffix=\".\"+AUDIO_FORMAT)\n",
    "                tf.write(r2.content)\n",
    "                tf.close()\n",
    "                print(f\"MINIMAX TTS合成成功！檔案: {tf.name}\")\n",
    "            else:\n",
    "                print(\"MINIMAX音檔下載失敗，狀態碼：\", r2.status_code)\n",
    "        else:\n",
    "            print(\"MINIMAX未取得音檔URL，API回應：\", data)\n",
    "    else:\n",
    "        print(\"MINIMAX API錯誤：\", base_resp.get(\"status_msg\", \"未知\"), \"\\nAPI回應：\", data)\n",
    "else:\n",
    "    print(\"MINIMAX TTS API失敗，狀態碼：\", r.status_code)\n",
    "    print(\"回應：\", r.text[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49bbf04-2f1a-41a9-bc8b-5b166d36912c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
